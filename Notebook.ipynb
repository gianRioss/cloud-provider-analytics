{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgoAlnI4kwdr","executionInfo":{"status":"ok","timestamp":1763569854036,"user_tz":180,"elapsed":36065,"user":{"displayName":"jose gianmarco mauricio rios","userId":"09430851862296446138"}},"outputId":"ab07a46f-d834-46d9-812e-9e01ab089b3e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# ⚠️ Ruta EXACTA a tu carpeta (tiene espacios)\n","SRC = \"/content/drive/MyDrive/mineria de datos II/proyecto1\"\n","\n","# Carpeta final del repo en Drive (puede ser distinta a la fuente)\n","REPO = \"/content/drive/MyDrive/cloud-provider-analytics\"  # puedes cambiar el nombre\n","\n","print(\"Origen (datos/notebook):\", SRC)\n","print(\"Repo destino:\", REPO)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ewaM9xkxB5a7","executionInfo":{"status":"ok","timestamp":1763571130425,"user_tz":180,"elapsed":39,"user":{"displayName":"jose gianmarco mauricio rios","userId":"09430851862296446138"}},"outputId":"b26c3cc0-bab3-488f-89f1-aeb4fa069f32"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Origen (datos/notebook): /content/drive/MyDrive/mineria de datos II/proyecto1\n","Repo destino: /content/drive/MyDrive/cloud-provider-analytics\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8uaScHFVLK4"},"outputs":[],"source":["!apt-get -y install openjdk-11-jdk-headless > /dev/null\n","\n","import os, subprocess, sys"]},{"cell_type":"code","source":["# 2) JAVA_HOME y path\n","java_home = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"JAVA_HOME\"] = java_home\n","os.environ[\"PATH\"] = f'{java_home}/bin:' + os.environ[\"PATH\"]"],"metadata":{"id":"ko3Wiqd_j3pk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3) Limpiar pyspark previo y reinstalar versión compatible\n","!pip -q uninstall -y pyspark py4j > /dev/null"],"metadata":{"id":"96-1aU8mj8BM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Spark 3.5.x funciona bien con Java 11 en Colab; si tu runtime es muy viejo, probaremos 3.4.1 como fallback.\n","target_version = \"3.5.1\"\n","code = !pip -q install pyspark=={target_version}\n","print(f\"pip pyspark=={target_version} -> OK\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kAOTcEskC40","executionInfo":{"status":"ok","timestamp":1762992921913,"user_tz":180,"elapsed":57351,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"06e5873f-5efd-436a-d374-932be95bc41d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pip pyspark==3.5.1 -> OK\n"]}]},{"cell_type":"code","source":["# 4) Verificar Java\n","print(\"JAVA_HOME =\", os.environ.get(\"JAVA_HOME\"))\n","!java -version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkpvGiLCkTXo","executionInfo":{"status":"ok","timestamp":1762992932224,"user_tz":180,"elapsed":111,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"b9a69c79-6272-4abf-c87d-f8b99aa46f60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["JAVA_HOME = /usr/lib/jvm/java-11-openjdk-amd64\n","openjdk version \"11.0.28\" 2025-07-15\n","OpenJDK Runtime Environment (build 11.0.28+6-post-Ubuntu-1ubuntu122.04.1)\n","OpenJDK 64-Bit Server VM (build 11.0.28+6-post-Ubuntu-1ubuntu122.04.1, mixed mode, sharing)\n"]}]},{"cell_type":"code","source":["# 5) Iniciar Spark\n","from pyspark.sql import SparkSession\n","spark = (SparkSession.builder\n","         .appName(\"CloudProviderAnalytics\")\n","         .config(\"spark.sql.shuffle.partitions\", \"200\")\n","         .config(\"spark.driver.memory\", \"4g\")\n","         .config(\"spark.executor.memory\", \"4g\")\n","         .getOrCreate())\n","\n","from pyspark.sql import functions as F\n","from pyspark.sql import types as T\n","\n","print(\"Spark version:\", spark.version)\n","print(\"Context OK ✅\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aouiO65ZkW0A","executionInfo":{"status":"ok","timestamp":1762992956307,"user_tz":180,"elapsed":10659,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"5ac17bef-d07d-431f-8be4-8ca936a2bd61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Spark version: 3.5.1\n","Context OK ✅\n"]}]},{"cell_type":"markdown","source":["**bronze**"],"metadata":{"id":"8bN5cl0rlAkk"}},{"cell_type":"code","source":["# === BRONZE BATCH: CSV -> PARQUET ===\n","from pyspark.sql import functions as F, types as T\n","import os\n","\n","#  RUTA A TU DRIVE\n","BASE_LANDING = \"/content/drive/MyDrive/mineria de datos II/proyecto1\"\n","\n","LANDING = {\n","    \"customers\": f\"{BASE_LANDING}/customers_orgs.csv\",\n","    \"users\":     f\"{BASE_LANDING}/users.csv\",\n","    \"resources\": f\"{BASE_LANDING}/resources.csv\",\n","    \"tickets\":   f\"{BASE_LANDING}/support_tickets.csv\",\n","    \"marketing\": f\"{BASE_LANDING}/marketing_touches.csv\",\n","    \"nps\":       f\"{BASE_LANDING}/nps_surveys.csv\",\n","    \"billing\":   f\"{BASE_LANDING}/billing_monthly.csv\",\n","}\n","\n","BASE_WORK = \"/content/datalake\"\n","BRONZE = f\"{BASE_WORK}/bronze\"\n","os.makedirs(BRONZE, exist_ok=True)\n","\n","schema_customers = T.StructType([\n","    T.StructField(\"org_id\", T.StringType()),\n","    T.StructField(\"org_name\", T.StringType()),\n","    T.StructField(\"industry\", T.StringType()),\n","    T.StructField(\"region\", T.StringType()),\n","    T.StructField(\"plan\", T.StringType()),\n","    T.StructField(\"nps_last\", T.DoubleType()),\n","    T.StructField(\"created_at\", T.StringType())\n","])\n","\n","schema_users = T.StructType([\n","    T.StructField(\"user_id\", T.StringType()),\n","    T.StructField(\"org_id\", T.StringType()),\n","    T.StructField(\"role\", T.StringType()),\n","    T.StructField(\"is_active\", T.StringType()),\n","    T.StructField(\"last_login_ts\", T.StringType())\n","])\n","\n","schema_resources = T.StructType([\n","    T.StructField(\"resource_id\", T.StringType()),\n","    T.StructField(\"org_id\", T.StringType()),\n","    T.StructField(\"service\", T.StringType()),\n","    T.StructField(\"region\", T.StringType()),\n","    T.StructField(\"created_ts\", T.StringType())\n","])\n","\n","schema_tickets = T.StructType([\n","    T.StructField(\"ticket_id\", T.StringType()),\n","    T.StructField(\"org_id\", T.StringType()),\n","    T.StructField(\"category\", T.StringType()),\n","    T.StructField(\"severity\", T.StringType()),\n","    T.StructField(\"opened_ts\", T.StringType()),\n","    T.StructField(\"closed_ts\", T.StringType()),\n","    T.StructField(\"sla_breached\", T.StringType()),\n","    T.StructField(\"csat\", T.DoubleType())\n","])\n","\n","schema_marketing = T.StructType([\n","    T.StructField(\"touch_id\", T.StringType()),\n","    T.StructField(\"org_id\", T.StringType()),\n","    T.StructField(\"channel\", T.StringType()),\n","    T.StructField(\"touch_ts\", T.StringType()),\n","    T.StructField(\"converted\", T.StringType())\n","])\n","\n","schema_nps = T.StructType([\n","    T.StructField(\"org_id\", T.StringType()),\n","    T.StructField(\"survey_ts\", T.StringType()),\n","    T.StructField(\"score\", T.DoubleType())\n","])\n","\n","schema_billing = T.StructType([\n","    T.StructField(\"org_id\", T.StringType()),\n","    T.StructField(\"month\", T.StringType()),        # yyyy-MM\n","    T.StructField(\"subtotal_usd\", T.DoubleType()),\n","    T.StructField(\"credits_usd\", T.DoubleType()),\n","    T.StructField(\"tax_usd\", T.DoubleType()),\n","    T.StructField(\"fx_rate\", T.DoubleType()),\n","    T.StructField(\"currency\", T.StringType())\n","])\n","\n","def add_ingest_cols(df):\n","    return (df.withColumn(\"ingest_ts\", F.current_timestamp())\n","              .withColumn(\"source_file\", F.input_file_name()))\n","\n","def batch_to_bronze(csv_path, schema, out_path, partition_cols):\n","    df = (spark.read.option(\"header\", True).schema(schema).csv(csv_path))\n","    df = add_ingest_cols(df)\n","    # normalizaciones de timestamps si existen\n","    for c in [\"created_at\",\"last_login_ts\",\"created_ts\",\"opened_ts\",\"closed_ts\",\"touch_ts\",\"survey_ts\"]:\n","        if c in df.columns:\n","            df = df.withColumn(c, F.to_timestamp(F.col(c)))\n","    # snapshot para particionar si hace falta\n","    if \"snapshot_date\" not in df.columns:\n","        df = df.withColumn(\"snapshot_date\", F.current_date())\n","\n","    writer = df.write.mode(\"overwrite\").partitionBy(*partition_cols)\n","    writer.parquet(out_path)\n","    return df\n","\n","bronze_paths = {\n","    \"customers\": f\"{BRONZE}/customers\",\n","    \"users\":     f\"{BRONZE}/users\",\n","    \"resources\": f\"{BRONZE}/resources\",\n","    \"tickets\":   f\"{BRONZE}/tickets\",\n","    \"marketing\": f\"{BRONZE}/marketing\",\n","    \"nps\":       f\"{BRONZE}/nps\",\n","    \"billing\":   f\"{BRONZE}/billing\",\n","}\n","\n","_ = batch_to_bronze(LANDING[\"customers\"], schema_customers, bronze_paths[\"customers\"], [\"snapshot_date\"])\n","_ = batch_to_bronze(LANDING[\"users\"],     schema_users,     bronze_paths[\"users\"],     [\"snapshot_date\"])\n","_ = batch_to_bronze(LANDING[\"resources\"], schema_resources, bronze_paths[\"resources\"], [\"snapshot_date\"])\n","_ = batch_to_bronze(LANDING[\"tickets\"],   schema_tickets,   bronze_paths[\"tickets\"],   [\"snapshot_date\"])\n","_ = batch_to_bronze(LANDING[\"marketing\"], schema_marketing, bronze_paths[\"marketing\"], [\"snapshot_date\"])\n","_ = batch_to_bronze(LANDING[\"nps\"],       schema_nps,       bronze_paths[\"nps\"],       [\"snapshot_date\"])\n","_ = batch_to_bronze(LANDING[\"billing\"],   schema_billing,   bronze_paths[\"billing\"],   [\"month\"])\n","\n","print(\"✔ Batch → Bronze completado\")\n","\n","# sanity checks\n","for k,v in bronze_paths.items():\n","    try:\n","        cnt = spark.read.parquet(v).count()\n","        print(f\"{k:<10} -> {cnt} filas\")\n","    except Exception as e:\n","        print(f\"{k:<10} -> ERROR: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fLqGVGfak8z9","executionInfo":{"status":"ok","timestamp":1762993184778,"user_tz":180,"elapsed":32707,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"24c80bd6-2d21-4294-c707-0b31e520d44e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✔ Batch → Bronze completado\n","customers  -> 80 filas\n","users      -> 800 filas\n","resources  -> 400 filas\n","tickets    -> 1000 filas\n","marketing  -> 1500 filas\n","nps        -> 92 filas\n","billing    -> 240 filas\n"]}]},{"cell_type":"markdown","source":["Streaming → Bronze (JSON → Parquet con watermark + dedup + quarantine)"],"metadata":{"id":"arB5kscAl5lP"}},{"cell_type":"code","source":["# === BRONZE STREAMING: usage_events_stream ===\n","from pyspark.sql import functions as F, types as T\n","import os\n","\n","BASE_LANDING = \"/content/drive/MyDrive/mineria de datos II/proyecto1\"\n","EVENTS_DIR = f\"{BASE_LANDING}/usage_events_stream\"\n","\n","BASE_WORK = \"/content/datalake\"\n","BRONZE = f\"{BASE_WORK}/bronze\"\n","CHECKPOINTS = \"/content/checkpoints\"\n","QUARANTINE = f\"{BRONZE}/_quarantine\"\n","os.makedirs(CHECKPOINTS, exist_ok=True)\n","os.makedirs(QUARANTINE, exist_ok=True)\n","\n","schema_events = T.StructType([\n","    T.StructField(\"event_id\", T.StringType()),\n","    T.StructField(\"org_id\", T.StringType()),\n","    T.StructField(\"service\", T.StringType()),\n","    T.StructField(\"region\", T.StringType()),\n","    T.StructField(\"unit\", T.StringType()),\n","    T.StructField(\"value\", T.DoubleType()),\n","    T.StructField(\"cost_usd_increment\", T.DoubleType()),\n","    T.StructField(\"event_ts\", T.StringType()),\n","    T.StructField(\"schema_version\", T.IntegerType()),\n","    T.StructField(\"carbon_kg\", T.DoubleType()),\n","    T.StructField(\"genai_tokens\", T.DoubleType())\n","])\n","\n","raw_stream = (spark.readStream\n","              .schema(schema_events)\n","              .option(\"maxFilesPerTrigger\", 2)  # micro-lotes para demo\n","              .json(EVENTS_DIR))\n","\n","events = (raw_stream\n","    .withColumn(\"value\", F.col(\"value\").cast(\"double\"))\n","    .withColumn(\"cost_usd_increment\", F.col(\"cost_usd_increment\").cast(\"double\"))\n","    .withColumn(\"event_ts\", F.to_timestamp(\"event_ts\"))\n","    .withColumn(\"schema_version\", F.coalesce(F.col(\"schema_version\"), F.lit(1)))\n","    .withColumn(\"unit\", F.when(F.col(\"unit\").isNull() & F.col(\"value\").isNotNull(), F.lit(\"unitless\"))\n","                         .otherwise(F.col(\"unit\")))\n","    .withColumn(\"usage_date\", F.to_date(\"event_ts\"))\n","    .withColumn(\"ingest_ts\", F.current_timestamp())\n","    .withColumn(\"source_file\", F.input_file_name())\n",")\n","\n","valid_cond = (F.col(\"event_id\").isNotNull() & (F.col(\"cost_usd_increment\") >= F.lit(-0.01)))\n","valid = events.where(valid_cond)\n","quar  = (events.where(~valid_cond)\n","         .withColumn(\"error_reason\",\n","                     F.when(F.col(\"event_id\").isNull(),\"NULL_EVENT_ID\")\n","                      .when(F.col(\"cost_usd_increment\") < -0.01, \"NEGATIVE_COST\")\n","                      .otherwise(\"UNKNOWN\")))\n","\n","valid_dedup = (valid\n","    .withWatermark(\"event_ts\",\"2 days\")\n","    .dropDuplicates([\"event_id\"])\n",")\n","\n","bronze_events_path = f\"{BRONZE}/usage_events\"\n","\n","q_quar = (quar.writeStream\n","          .format(\"parquet\")\n","          .option(\"checkpointLocation\", f\"{CHECKPOINTS}/quarantine_events\")\n","          .option(\"path\", f\"{QUARANTINE}/usage_events\")\n","          .outputMode(\"append\")\n","          .start())\n","\n","q_bronze = (valid_dedup.writeStream\n","            .format(\"parquet\")\n","            .option(\"checkpointLocation\", f\"{CHECKPOINTS}/bronze_usage_events\")\n","            .option(\"path\", bronze_events_path)\n","            .partitionBy(\"usage_date\",\"service\")\n","            .outputMode(\"append\")\n","            .start())\n","\n","print(\"⏳ Streaming corriendo... procesando micro-lotes.\")\n","\n","import time\n","for i in range(6):\n","    time.sleep(10)\n","    lp = q_bronze.lastProgress\n","    rows = lp[\"numInputRows\"] if lp else 0\n","    print(f\"t+{(i+1)*10}s -> inputRows={rows}\")\n","\n","# Para ver lo que cayó ya:\n","try:\n","    df_bz = spark.read.parquet(bronze_events_path)\n","    print(\"Bronze events count:\", df_bz.count())\n","    df_bz.groupBy(\"usage_date\",\"service\").count().orderBy(\"usage_date\",\"service\").show(10, False)\n","except Exception as e:\n","    print(\"Aún no hay archivos en Bronze events:\", e)\n","\n","# (Parar cuando quieras)\n","# q_bronze.stop(); q_quar.stop()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vR95u3N4l6wv","executionInfo":{"status":"ok","timestamp":1762993497962,"user_tz":180,"elapsed":121221,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"affd56ee-5583-4458-be01-9f8ef45ba7e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["⏳ Streaming corriendo... procesando micro-lotes.\n","t+10s -> inputRows=0\n","t+20s -> inputRows=0\n","t+30s -> inputRows=0\n","t+40s -> inputRows=720\n","t+50s -> inputRows=720\n","t+60s -> inputRows=720\n","Bronze events count: 718\n","+----------+----------+-----+\n","|usage_date|service   |count|\n","+----------+----------+-----+\n","|NULL      |analytics |67   |\n","|NULL      |compute   |221  |\n","|NULL      |database  |112  |\n","|NULL      |genai     |81   |\n","|NULL      |networking|110  |\n","|NULL      |storage   |127  |\n","+----------+----------+-----+\n","\n"]}]},{"cell_type":"markdown","source":["parser robusto multi-patrón y relanzar el stream. También reescribimos lo ya procesado para corregir los NULL.\n","\n","Fix — Parser de timestamp + relanzar streaming"],"metadata":{"id":"Qpj3jpCYnXv8"}},{"cell_type":"code","source":["# === FIX STREAMING: parseo robusto de event_ts y reprocesamiento limpio ===\n","from pyspark.sql import functions as F, types as T\n","import shutil, os\n","\n","BASE_LANDING = \"/content/drive/MyDrive/mineria de datos II/proyecto1\"\n","EVENTS_DIR = f\"{BASE_LANDING}/usage_events_stream\"\n","\n","BASE_WORK = \"/content/datalake\"\n","BRONZE = f\"{BASE_WORK}/bronze\"\n","CHECKPOINTS = \"/content/checkpoints\"\n","QUARANTINE = f\"{BRONZE}/_quarantine\"\n","bronze_events_path = f\"{BRONZE}/usage_events\"\n","\n","# 0) Parar queries previas si siguen vivas\n","try:\n","    q_bronze.stop()\n","except: pass\n","try:\n","    q_quar.stop()\n","except: pass\n","\n","# 1) Limpiar solo lo del stream para reprocesar correcto\n","for p in [bronze_events_path, f\"{CHECKPOINTS}/bronze_usage_events\", f\"{CHECKPOINTS}/quarantine_events\", f\"{QUARANTINE}/usage_events\"]:\n","    try:\n","        shutil.rmtree(p)\n","    except FileNotFoundError:\n","        pass\n","os.makedirs(f\"{CHECKPOINTS}\", exist_ok=True)\n","os.makedirs(f\"{QUARANTINE}\", exist_ok=True)\n","\n","# 2) Esquema y lectura\n","schema_events = T.StructType([\n","    T.StructField(\"event_id\", T.StringType()),\n","    T.StructField(\"org_id\", T.StringType()),\n","    T.StructField(\"service\", T.StringType()),\n","    T.StructField(\"region\", T.StringType()),\n","    T.StructField(\"unit\", T.StringType()),\n","    T.StructField(\"value\", T.DoubleType()),\n","    T.StructField(\"cost_usd_increment\", T.DoubleType()),\n","    T.StructField(\"event_ts\", T.StringType()),     # mantenemos string; luego lo parseamos robusto\n","    T.StructField(\"schema_version\", T.IntegerType()),\n","    T.StructField(\"carbon_kg\", T.DoubleType()),\n","    T.StructField(\"genai_tokens\", T.DoubleType()),\n","    # posibles variantes por si algunos archivos usan otros nombres\n","    T.StructField(\"timestamp\", T.StringType()),\n","    T.StructField(\"time\", T.StringType()),\n","    T.StructField(\"event_time\", T.StringType()),\n","    T.StructField(\"event_unix\", T.LongType()),\n","    T.StructField(\"event_ms\", T.LongType())\n","])\n","\n","raw_stream = (spark.readStream\n","              .schema(schema_events)\n","              .option(\"maxFilesPerTrigger\", 2)\n","              .json(EVENTS_DIR))\n","\n","# 3) Parser robusto del timestamp (ISO8601 con y sin milis, con 'Z' o zona)\n","evt_str = F.coalesce(\n","    F.col(\"event_ts\"), F.col(\"timestamp\"), F.col(\"event_time\"), F.col(\"time\")\n",")\n","\n","evt_ts = F.coalesce(\n","    F.to_timestamp(evt_str, \"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\"),\n","    F.to_timestamp(evt_str, \"yyyy-MM-dd'T'HH:mm:ssXXX\"),\n","    F.to_timestamp(evt_str, \"yyyy-MM-dd HH:mm:ss\"),\n","    F.to_timestamp(evt_str)  # fallback genérico\n",")\n","\n","# fallback extra si vino epoch\n","evt_ts = F.coalesce(\n","    evt_ts,\n","    F.to_timestamp(F.from_unixtime(F.col(\"event_ms\")/1000.0)),\n","    F.to_timestamp(F.from_unixtime(F.col(\"event_unix\")))\n",")\n","\n","events = (raw_stream\n","    .withColumn(\"value\", F.col(\"value\").cast(\"double\"))\n","    .withColumn(\"cost_usd_increment\", F.col(\"cost_usd_increment\").cast(\"double\"))\n","    .withColumn(\"event_ts_parsed\", evt_ts)\n","    .withColumn(\"schema_version\", F.coalesce(F.col(\"schema_version\"), F.lit(1)))\n","    .withColumn(\"unit\", F.when(F.col(\"unit\").isNull() & F.col(\"value\").isNotNull(), F.lit(\"unitless\"))\n","                         .otherwise(F.col(\"unit\")))\n","    .withColumn(\"usage_date\", F.to_date(\"event_ts_parsed\"))\n","    .withColumn(\"ingest_ts\", F.current_timestamp())\n","    .withColumn(\"source_file\", F.input_file_name())\n",")\n","\n","valid_cond = (F.col(\"event_id\").isNotNull() & (F.col(\"cost_usd_increment\") >= F.lit(-0.01)))\n","valid = events.where(valid_cond)\n","quar  = (events.where(~valid_cond)\n","         .withColumn(\"error_reason\",\n","                     F.when(F.col(\"event_id\").isNull(),\"NULL_EVENT_ID\")\n","                      .when(F.col(\"cost_usd_increment\") < -0.01, \"NEGATIVE_COST\")\n","                      .otherwise(\"UNKNOWN\")))\n","\n","valid_dedup = (valid\n","    .withWatermark(\"event_ts_parsed\",\"2 days\")\n","    .dropDuplicates([\"event_id\"])\n",")\n","\n","q_quar = (quar.writeStream\n","          .format(\"parquet\")\n","          .option(\"checkpointLocation\", f\"{CHECKPOINTS}/quarantine_events\")\n","          .option(\"path\", f\"{QUARANTINE}/usage_events\")\n","          .outputMode(\"append\")\n","          .start())\n","\n","q_bronze = (valid_dedup.writeStream\n","            .format(\"parquet\")\n","            .option(\"checkpointLocation\", f\"{CHECKPOINTS}/bronze_usage_events\")\n","            .option(\"path\", bronze_events_path)\n","            .partitionBy(\"usage_date\",\"service\")\n","            .outputMode(\"append\")\n","            .start())\n","\n","print(\"⏳ Streaming relanzado con parser robusto. Esperando micro-lotes...\")\n","\n","import time\n","for i in range(6):\n","    time.sleep(10)\n","    lp = q_bronze.lastProgress\n","    rows = lp[\"numInputRows\"] if lp else 0\n","    print(f\"t+{(i+1)*10}s -> inputRows={rows}\")\n","\n","# Chequeo rápido\n","try:\n","    df_bz = spark.read.parquet(bronze_events_path)\n","    print(\"Bronze events count:\", df_bz.count())\n","    df_bz.groupBy(\"usage_date\",\"service\").count().orderBy(\"usage_date\",\"service\").show(12, False)\n","except Exception as e:\n","    print(\"Aún no hay archivos en Bronze events:\", e)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--vb8rY5nY7M","executionInfo":{"status":"ok","timestamp":1762993858161,"user_tz":180,"elapsed":93982,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"f2cabb9c-686a-4247-829b-87b3fd8d1654"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["⏳ Streaming relanzado con parser robusto. Esperando micro-lotes...\n","t+10s -> inputRows=0\n","t+20s -> inputRows=0\n","t+30s -> inputRows=720\n","t+40s -> inputRows=720\n","t+50s -> inputRows=720\n","t+60s -> inputRows=720\n","Bronze events count: 1464\n","+----------+----------+-----+\n","|usage_date|service   |count|\n","+----------+----------+-----+\n","|2025-07-03|analytics |4    |\n","|2025-07-03|compute   |6    |\n","|2025-07-03|database  |5    |\n","|2025-07-03|networking|4    |\n","|2025-07-03|storage   |5    |\n","|2025-07-04|analytics |4    |\n","|2025-07-04|compute   |7    |\n","|2025-07-04|database  |6    |\n","|2025-07-04|genai     |2    |\n","|2025-07-04|networking|2    |\n","|2025-07-04|storage   |5    |\n","|2025-07-05|analytics |2    |\n","+----------+----------+-----+\n","only showing top 12 rows\n","\n"]}]},{"cell_type":"markdown","source":["Celda única — Silver (dimensiones, facts, usage y anomalías)"],"metadata":{"id":"bwWXlUrioPHb"}},{"cell_type":"code","source":["# === SILVER END-TO-END (con fix de create_map) ===\n","from pyspark.sql import functions as F, types as T\n","from pyspark.sql.window import Window as W\n","import os\n","\n","BRONZE = \"/content/datalake/bronze\"\n","SILVER = \"/content/datalake/silver\"\n","os.makedirs(SILVER, exist_ok=True)\n","\n","# --- Normalización (FIX: create_map con *args) ---\n","REGION_MAP = {\n","    \"us-east-1\":\"us-east-1\",\"us_east_1\":\"us-east-1\",\"use1\":\"us-east-1\",\n","    \"eu-west-1\":\"eu-west-1\",\"euw1\":\"eu-west-1\",\n","    \"sa-east-1\":\"sa-east-1\",\"sae1\":\"sa-east-1\"\n","}\n","SERVICE_MAP = {\n","    \"compute\":\"compute\",\"vm\":\"compute\",\"ec2\":\"compute\",\n","    \"storage\":\"storage\",\"s3\":\"storage\",\n","    \"database\":\"database\",\"db\":\"database\",\n","    \"networking\":\"networking\",\"vpc\":\"networking\",\n","    \"analytics\":\"analytics\",\n","    \"genai\":\"genai\",\"llm\":\"genai\"\n","}\n","\n","def dict_map(col, mapping):\n","    pairs = []\n","    for k, v in mapping.items():\n","        pairs += [F.lit(k.lower()), F.lit(v)]\n","    # Si el mapping está vacío, devolvemos lower(col)\n","    return F.coalesce(F.create_map(*pairs)[F.lower(col)] if pairs else F.lower(col), F.lower(col))\n","\n","def norm_region(c):  return dict_map(c, REGION_MAP)\n","def norm_service(c): return dict_map(c, SERVICE_MAP)\n","\n","def write_silver(df, path, partition_cols=None, mode=\"overwrite\"):\n","    w = df.write.mode(mode)\n","    if partition_cols: w = w.partitionBy(*partition_cols)\n","    w.parquet(path)\n","\n","# --- 1) Dimensiones ---\n","dim_orgs = (spark.read.parquet(f\"{BRONZE}/customers\")\n","  .withColumn(\"org_name\", F.initcap(\"org_name\"))\n","  .withColumn(\"industry\", F.lower(\"industry\"))\n","  .withColumn(\"region\",  norm_region(F.col(\"region\")))\n","  .withColumn(\"plan\",    F.lower(\"plan\"))\n","  .withColumn(\"nps_last\", F.col(\"nps_last\").cast(\"double\"))\n","  .select(\"org_id\",\"org_name\",\"industry\",\"region\",\"plan\",\"nps_last\",\"ingest_ts\",\"source_file\",\"snapshot_date\")\n","  .dropDuplicates([\"org_id\"])\n",")\n","write_silver(dim_orgs, f\"{SILVER}/dim_orgs\")\n","\n","dim_users = (spark.read.parquet(f\"{BRONZE}/users\")\n","  .withColumn(\"is_active\", F.when(F.lower(\"is_active\").isin(\"true\",\"1\",\"yes\"), F.lit(True)).otherwise(F.lit(False)))\n","  .select(\"user_id\",\"org_id\",\"role\",\"is_active\",\"last_login_ts\",\"snapshot_date\",\"ingest_ts\",\"source_file\")\n",")\n","write_silver(dim_users, f\"{SILVER}/dim_users\")\n","\n","dim_resources = (spark.read.parquet(f\"{BRONZE}/resources\")\n","  .withColumn(\"service\", norm_service(F.col(\"service\")))\n","  .withColumn(\"region\",  norm_region(F.col(\"region\")))\n","  .select(\"resource_id\",\"org_id\",\"service\",\"region\",\"created_ts\",\"snapshot_date\",\"ingest_ts\",\"source_file\")\n",")\n","write_silver(dim_resources, f\"{SILVER}/dim_resources\")\n","\n","print(\"✔ Silver dimensiones: dim_orgs, dim_users, dim_resources\")\n","\n","# --- 2) Fact tickets diarios (Soporte) ---\n","bz_tickets = spark.read.parquet(f\"{BRONZE}/tickets\")\n","fact_tickets_daily = (bz_tickets\n","  .withColumn(\"opened_date\", F.to_date(\"opened_ts\"))\n","  .withColumn(\"sev\", F.lower(\"severity\"))\n","  .withColumn(\"sla_breached\", F.when(F.lower(\"sla_breached\").isin(\"true\",\"1\",\"yes\"), F.lit(1)).otherwise(F.lit(0)))\n","  .withColumn(\"csat\", F.col(\"csat\").cast(\"double\"))\n","  .groupBy(\"org_id\",\"opened_date\",\"sev\")\n","  .agg(\n","      F.count(\"*\").alias(\"tickets_opened\"),\n","      F.sum(\"sla_breached\").alias(\"sla_breach_count\"),\n","      F.avg(\"csat\").alias(\"csat_avg\")\n","  ).withColumnRenamed(\"opened_date\",\"date\")\n",")\n","write_silver(fact_tickets_daily, f\"{SILVER}/fact_tickets_daily\", [\"date\"])\n","print(\"✔ Silver soporte: fact_tickets_daily\")\n","\n","# --- 3) Billing normalizado (FinOps) ---\n","bz_bill = spark.read.parquet(f\"{BRONZE}/billing\")\n","fact_billing_monthly = (bz_bill\n","  .withColumn(\"fx_rate\", F.coalesce(F.col(\"fx_rate\").cast(\"double\"), F.lit(1.0)))\n","  .withColumn(\"subtotal_usd\", F.col(\"subtotal_usd\").cast(\"double\"))\n","  .withColumn(\"credits_usd\",  F.col(\"credits_usd\").cast(\"double\"))\n","  .withColumn(\"tax_usd\",      F.col(\"tax_usd\").cast(\"double\"))\n","  .withColumn(\"revenue_usd\", (F.col(\"subtotal_usd\") - F.col(\"credits_usd\") + F.col(\"tax_usd\")) * F.col(\"fx_rate\"))\n","  .select(\"org_id\",\"month\",\"revenue_usd\",\"subtotal_usd\",\"credits_usd\",\"tax_usd\",\"fx_rate\",\"currency\")\n",")\n","write_silver(fact_billing_monthly, f\"{SILVER}/fact_billing_monthly\", [\"month\"])\n","print(\"✔ Silver finops: fact_billing_monthly\")\n","\n","# --- 4) NPS por fecha ---\n","bz_nps = spark.read.parquet(f\"{BRONZE}/nps\")\n","nps_by_org_date = (bz_nps\n","  .withColumn(\"date\", F.to_date(\"survey_ts\"))\n","  .groupBy(\"org_id\",\"date\").agg(F.avg(\"score\").alias(\"nps_avg\"))\n",")\n","write_silver(nps_by_org_date, f\"{SILVER}/nps_by_org_date\", [\"date\"])\n","print(\"✔ Silver nps_by_org_date\")\n","\n","# --- 5) Usage diario por servicio (FinOps/Producto) ---\n","events_path = f\"{BRONZE}/usage_events\"\n","has_events = False\n","try:\n","    _ = spark.read.parquet(events_path).limit(1).count()\n","    has_events = True\n","except Exception:\n","    has_events = False\n","\n","if has_events:\n","    ev = spark.read.parquet(events_path)\n","    ev = (ev\n","      .withColumn(\"service\", norm_service(F.col(\"service\")))\n","      .withColumn(\"region\",  norm_region(F.col(\"region\")))\n","      .withColumn(\"value\", F.col(\"value\").cast(\"double\"))\n","      .withColumn(\"cost_usd_increment\", F.col(\"cost_usd_increment\").cast(\"double\"))\n","      .withColumn(\"carbon_kg\", F.col(\"carbon_kg\").cast(\"double\"))\n","      .withColumn(\"genai_tokens\", F.col(\"genai_tokens\").cast(\"double\"))\n","    )\n","    if \"usage_date\" not in ev.columns or ev.filter(F.col(\"usage_date\").isNotNull()).count()==0:\n","        ts_col = None\n","        for c in [\"event_ts_parsed\",\"event_ts\"]:\n","            if c in ev.columns:\n","                ts_col = c; break\n","        ev = ev.withColumn(\"usage_date\", F.to_date(ts_col) if ts_col else F.current_date())\n","\n","    usage_daily = (ev.groupBy(\"org_id\",\"usage_date\",\"service\")\n","      .agg(\n","        F.sum(\"cost_usd_increment\").alias(\"daily_cost_usd\"),\n","        F.sum(F.when(F.lower(\"unit\")==\"request\", F.col(\"value\")).otherwise(F.lit(0.0))).alias(\"requests\"),\n","        F.sum(F.when(F.lower(\"unit\").isin(\"cpu_hour\",\"cpu_hours\"), F.col(\"value\")).otherwise(F.lit(0.0))).alias(\"cpu_hours\"),\n","        F.sum(F.when(F.lower(\"unit\").isin(\"gb_hour\",\"gb_hours\",\"storage_gb_hours\"), F.col(\"value\")).otherwise(F.lit(0.0))).alias(\"storage_gb_hours\"),\n","        F.sum(F.coalesce(F.col(\"genai_tokens\"), F.lit(0.0))).alias(\"genai_tokens\"),\n","        F.sum(F.coalesce(F.col(\"carbon_kg\"), F.lit(0.0))).alias(\"carbon_kg\")\n","      )\n","      .withColumnRenamed(\"usage_date\",\"date\")\n","    )\n","    write_silver(usage_daily, f\"{SILVER}/usage_daily_by_service\", [\"date\",\"service\"])\n","    print(\"✔ Silver usage_daily_by_service\")\n","\n","    # --- 6) Anomalías de costo (percentiles + z-score + MAD) ---\n","    ud = spark.read.parquet(f\"{SILVER}/usage_daily_by_service\")\n","\n","    percs = (ud.groupBy(\"service\")\n","               .agg(F.expr(\"percentile_approx(daily_cost_usd, array(0.95,0.99)) as ptiles\"))\n","               .withColumn(\"p95\", F.col(\"ptiles\")[0])\n","               .withColumn(\"p99\", F.col(\"ptiles\")[1])\n","               .select(\"service\",\"p95\",\"p99\"))\n","\n","    stats = (ud.groupBy(\"service\")\n","               .agg(F.avg(\"daily_cost_usd\").alias(\"mu\"),\n","                    F.stddev_pop(\"daily_cost_usd\").alias(\"sigma\")))\n","    udz = (ud.join(stats, \"service\",\"left\")\n","             .withColumn(\"zscore\", (F.col(\"daily_cost_usd\")-F.col(\"mu\"))/F.col(\"sigma\")))\n","\n","    med = ud.groupBy(\"service\").agg(F.expr(\"percentile_approx(daily_cost_usd, 0.5)\").alias(\"med\"))\n","    mad = (ud.join(med,\"service\")\n","             .withColumn(\"abs_dev\", F.abs(F.col(\"daily_cost_usd\")-F.col(\"med\")))\n","             .groupBy(\"service\",\"med\")\n","             .agg(F.expr(\"percentile_approx(abs_dev, 0.5)\").alias(\"mad\")))\n","    udm = (ud.join(mad,\"service\")\n","             .withColumn(\"mad_score\", (F.col(\"daily_cost_usd\")-F.col(\"med\"))/F.col(\"mad\")))\n","\n","    cost_anomaly = (ud\n","      .join(percs, \"service\", \"left\")\n","      .join(udz.select(\"service\",\"date\",\"org_id\",\"zscore\"), [\"service\",\"date\",\"org_id\"], \"left\")\n","      .join(udm.select(\"service\",\"date\",\"org_id\",\"mad_score\"), [\"service\",\"date\",\"org_id\"], \"left\")\n","      .withColumn(\"flag_p99\", F.col(\"daily_cost_usd\") > F.col(\"p99\"))\n","      .withColumn(\"flag_z3\",  F.col(\"zscore\") > F.lit(3))\n","      .withColumn(\"flag_mad3\",F.col(\"mad_score\") > F.lit(3))\n","      .withColumn(\"anomaly_flag\", (F.col(\"flag_p99\") | F.col(\"flag_z3\") | F.col(\"flag_mad3\")).cast(\"boolean\"))\n","    )\n","    write_silver(cost_anomaly, f\"{SILVER}/cost_anomaly_mart\", [\"date\",\"service\"])\n","    print(\"✔ Silver cost_anomaly_mart\")\n","else:\n","    print(\"⚠ No se encontraron eventos en Bronze (/bronze/usage_events). Se salta usage/anomalías por ahora.\")\n","\n","# --- Vistas rápidas ---\n","print(\"\\n=== CHECKS ===\")\n","spark.read.parquet(f\"{SILVER}/dim_orgs\").orderBy(\"org_id\").show(5, False)\n","spark.read.parquet(f\"{SILVER}/fact_tickets_daily\").orderBy(\"date\",\"org_id\",\"sev\").show(5, False)\n","spark.read.parquet(f\"{SILVER}/fact_billing_monthly\").orderBy(\"month\",\"org_id\").show(5, False)\n","spark.read.parquet(f\"{SILVER}/nps_by_org_date\").orderBy(\"date\",\"org_id\").show(5, False)\n","\n","try:\n","    spark.read.parquet(f\"{SILVER}/usage_daily_by_service\").orderBy(\"date\",\"org_id\",\"service\").show(5, False)\n","    spark.read.parquet(f\"{SILVER}/cost_anomaly_mart\").orderBy(F.desc(\"anomaly_flag\"),F.desc(\"daily_cost_usd\")).show(5, False)\n","except Exception as e:\n","    print(\"Usage/Anomalías aún no disponibles:\", e)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7tvfvc9opAQP","executionInfo":{"status":"ok","timestamp":1762994712601,"user_tz":180,"elapsed":267539,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"e4eec84c-0059-4e06-8d42-41d2dd14c7ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✔ Silver dimensiones: dim_orgs, dim_users, dim_resources\n","✔ Silver soporte: fact_tickets_daily\n","✔ Silver finops: fact_billing_monthly\n","✔ Silver nps_by_org_date\n","✔ Silver usage_daily_by_service\n","✔ Silver cost_anomaly_mart\n","\n","=== CHECKS ===\n","+------------+--------------+----------+----------+----------+--------+--------------------------+------------------------------------------------------------------------------------+-------------+\n","|org_id      |org_name      |industry  |region    |plan      |nps_last|ingest_ts                 |source_file                                                                         |snapshot_date|\n","+------------+--------------+----------+----------+----------+--------+--------------------------+------------------------------------------------------------------------------------+-------------+\n","|org_0lvsnujz|Nova Cloud 45 |retail    |us-east   |standard  |NULL    |2025-11-13 00:19:17.985387|file:///content/drive/MyDrive/mineria%20de%20datos%20II/proyecto1/customers_orgs.csv|2025-11-13   |\n","|org_0lzjjege|Alpha Cloud 77|media     |eu-west   |standard  |NULL    |2025-11-13 00:19:17.985387|file:///content/drive/MyDrive/mineria%20de%20datos%20II/proyecto1/customers_orgs.csv|2025-11-13   |\n","|org_1n13jcat|Nimbus Tech 64|healthcare|us-east   |free      |NULL    |2025-11-13 00:19:17.985387|file:///content/drive/MyDrive/mineria%20de%20datos%20II/proyecto1/customers_orgs.csv|2025-11-13   |\n","|org_1swjckjl|Beta Tech 57  |government|eu-west   |standard  |NULL    |2025-11-13 00:19:17.985387|file:///content/drive/MyDrive/mineria%20de%20datos%20II/proyecto1/customers_orgs.csv|2025-11-13   |\n","|org_1t2tala7|Gamma Data 15 |media     |eu-central|enterprise|NULL    |2025-11-13 00:19:17.985387|file:///content/drive/MyDrive/mineria%20de%20datos%20II/proyecto1/customers_orgs.csv|2025-11-13   |\n","+------------+--------------+----------+----------+----------+--------+--------------------------+------------------------------------------------------------------------------------+-------------+\n","only showing top 5 rows\n","\n","+------------+------+--------------+----------------+--------+----------+\n","|org_id      |sev   |tickets_opened|sla_breach_count|csat_avg|date      |\n","+------------+------+--------------+----------------+--------+----------+\n","|org_chj755nf|low   |1             |0               |NULL    |2025-05-09|\n","|org_xll4zklo|medium|1             |0               |NULL    |2025-05-09|\n","|org_1n13jcat|low   |1             |0               |NULL    |2025-05-10|\n","|org_5lxo6qji|low   |1             |0               |NULL    |2025-05-10|\n","|org_874frhoc|medium|1             |0               |NULL    |2025-05-10|\n","+------------+------+--------------+----------------+--------+----------+\n","only showing top 5 rows\n","\n","+------------+-----------+------------+-----------+-------+-------+--------+------------+\n","|org_id      |revenue_usd|subtotal_usd|credits_usd|tax_usd|fx_rate|currency|month       |\n","+------------+-----------+------------+-----------+-------+-------+--------+------------+\n","|inv_ebxgkya3|NULL       |NULL        |1600.22    |21.0   |336.05 |USD     |org_0lvsnujz|\n","|inv_poqbt55r|NULL       |NULL        |1316.02    |NULL   |276.36 |ARS     |org_0lvsnujz|\n","|inv_z5ncy31z|NULL       |NULL        |675.07     |NULL   |141.77 |USD     |org_0lvsnujz|\n","|inv_87m5c6re|NULL       |NULL        |319.01     |5.42   |66.99  |ARS     |org_0lzjjege|\n","|inv_aguucqb3|NULL       |NULL        |1683.69    |16.87  |353.57 |ARS     |org_0lzjjege|\n","+------------+-----------+------------+-----------+-------+-------+--------+------------+\n","only showing top 5 rows\n","\n","+------------+-------+----------+\n","|org_id      |nps_avg|date      |\n","+------------+-------+----------+\n","|org_8mdd4v30|19.0   |2025-05-24|\n","|org_afeyuhz1|NULL   |2025-05-24|\n","|org_dhylurtp|34.0   |2025-05-26|\n","|org_pac56t4u|48.0   |2025-05-28|\n","|org_zhwjr64d|NULL   |2025-05-28|\n","+------------+-------+----------+\n","only showing top 5 rows\n","\n","+------------+--------------+--------+---------+----------------+------------+---------+----------+---------+\n","|org_id      |daily_cost_usd|requests|cpu_hours|storage_gb_hours|genai_tokens|carbon_kg|date      |service  |\n","+------------+--------------+--------+---------+----------------+------------+---------+----------+---------+\n","|org_0lvsnujz|0.0           |0.0     |0.0      |0.0             |0.0         |0.0      |2025-07-03|database |\n","|org_1swjckjl|0.1025        |0.0     |0.0      |0.0             |0.0         |0.0      |2025-07-03|database |\n","|org_253j2d54|0.1304        |0.0     |0.0      |0.0             |0.0         |0.0      |2025-07-03|analytics|\n","|org_5935a0l7|0.1532        |0.0     |0.0      |3.3199          |0.0         |0.0      |2025-07-03|database |\n","|org_9t84azyt|3.1272        |0.0     |0.0      |0.0             |0.0         |0.0      |2025-07-03|storage  |\n","+------------+--------------+--------+---------+----------------+------------+---------+----------+---------+\n","only showing top 5 rows\n","\n","+------------+--------------+--------+---------+----------------+------------+-------------------+------------------+--------+------------------+------------------+--------+-------+---------+------------+----------+---------+\n","|org_id      |daily_cost_usd|requests|cpu_hours|storage_gb_hours|genai_tokens|carbon_kg          |p95               |p99     |zscore            |mad_score         |flag_p99|flag_z3|flag_mad3|anomaly_flag|date      |service  |\n","+------------+--------------+--------+---------+----------------+------------+-------------------+------------------+--------+------------------+------------------+--------+-------+---------+------------+----------+---------+\n","|org_d14ve92m|181.2338      |0.0     |0.0      |0.0             |0.0         |0.0242             |20.0437           |169.0774|8.97172682231394  |32.41555567951507 |true    |true   |true     |true        |2025-07-20|analytics|\n","|org_c11ertj5|170.7746      |0.0     |0.0      |5.2164          |0.0         |0.09504300000000002|26.511899999999997|48.8655 |13.37419726907924 |26.454971629944552|true    |true   |true     |true        |2025-08-31|compute  |\n","|org_253j2d54|169.0774      |0.0     |0.0      |0.0             |0.0         |0.0236             |20.0437           |169.0774|8.342825163375952 |30.155203510533465|false   |true   |true     |true        |2025-08-14|analytics|\n","|org_kdgigatj|128.2206      |0.0     |0.0      |0.0             |0.0         |0.0236             |13.495000000000001|25.6137 |13.996432890514052|31.447701939227358|true    |true   |true     |true        |2025-08-26|database |\n","|org_nam148p0|58.2786       |0.0     |0.0      |0.0             |0.0         |0.1456             |26.511899999999997|48.8655 |4.129351649302805 |8.269685262119914 |true    |true   |true     |true        |2025-08-30|compute  |\n","+------------+--------------+--------+---------+----------------+------------+-------------------+------------------+--------+------------------+------------------+--------+-------+---------+------------+----------+---------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"markdown","source":["gold\n"],"metadata":{"id":"CHeK7PFrsgF2"}},{"cell_type":"code","source":["# === GOLD (Parquet) DESDE SILVER — Query-first, idempotente ===\n","from pyspark.sql import functions as F\n","import os, re\n","\n","SILVER = \"/content/datalake/silver\"\n","GOLD   = \"/content/datalake/gold\"\n","os.makedirs(GOLD, exist_ok=True)\n","\n","def write_gold(df, path, partition_cols=None, mode=\"overwrite\"):\n","    w = df.write.mode(mode)\n","    if partition_cols: w = w.partitionBy(*partition_cols)\n","    w.parquet(path)\n","\n","# 1) FinOps: org_daily_usage_by_service\n","usage = spark.read.parquet(f\"{SILVER}/usage_daily_by_service\")\n","gold_usage = (usage\n","    .select(\n","        \"org_id\",\"date\",\"service\",\n","        F.coalesce(\"daily_cost_usd\", F.lit(0.0)).alias(\"daily_cost_usd\"),\n","        F.coalesce(\"requests\", F.lit(0.0)).alias(\"requests\"),\n","        F.coalesce(\"cpu_hours\", F.lit(0.0)).alias(\"cpu_hours\"),\n","        F.coalesce(\"storage_gb_hours\", F.lit(0.0)).alias(\"storage_gb_hours\"),\n","        F.coalesce(\"genai_tokens\", F.lit(0.0)).alias(\"genai_tokens\"),\n","        F.coalesce(\"carbon_kg\", F.lit(0.0)).alias(\"carbon_kg\"),\n","    )\n",")\n","write_gold(gold_usage, f\"{GOLD}/org_daily_usage_by_service\", [\"date\",\"service\"])\n","print(\"✔ Gold: org_daily_usage_by_service\")\n","\n","# 2) FinOps: revenue_by_org_month  (con fix si 'month' y 'org_id' vinieron invertidos)\n","bill = spark.read.parquet(f\"{SILVER}/fact_billing_monthly\")\n","def looks_like_yyyymm(s): return bool(re.match(r\"^\\d{4}-\\d{2}$\", str(s or \"\")))\n","sample = bill.select(\"org_id\",\"month\").limit(50).collect()\n","need_swap = any(m is not None and not looks_like_yyyymm(m) for (_,m) in [(r[\"org_id\"],r[\"month\"]) for r in sample])\n","\n","if need_swap:\n","    bill = (bill\n","        .withColumnRenamed(\"org_id\",\"_tmp_org\")\n","        .withColumnRenamed(\"month\",\"_tmp_month\")\n","        .withColumn(\"org_id\", F.col(\"_tmp_month\"))\n","        .withColumn(\"month\",  F.col(\"_tmp_org\"))\n","        .drop(\"_tmp_org\",\"_tmp_month\")\n","    )\n","bill = bill.withColumn(\"month\", F.col(\"month\").cast(\"string\"))\n","gold_revenue = bill.select(\"org_id\",\"month\",\"revenue_usd\",\"subtotal_usd\",\"credits_usd\",\"tax_usd\",\"fx_rate\",\"currency\")\n","write_gold(gold_revenue, f\"{GOLD}/revenue_by_org_month\", [\"month\"])\n","print(\"✔ Gold: revenue_by_org_month\", \"(swap aplicado)\" if need_swap else \"\")\n","\n","# 3) FinOps: cost_anomaly_mart\n","anom = spark.read.parquet(f\"{SILVER}/cost_anomaly_mart\")\n","gold_anomaly = (anom.select(\n","    \"org_id\",\"date\",\"service\",\"daily_cost_usd\",\"zscore\",\"mad_score\",\"p95\",\"p99\",\n","    \"flag_p99\",\"flag_z3\",\"flag_mad3\",\"anomaly_flag\"\n","))\n","write_gold(gold_anomaly, f\"{GOLD}/cost_anomaly_mart\", [\"date\",\"service\"])\n","print(\"✔ Gold: cost_anomaly_mart\")\n","\n","# 4) Soporte: tickets_by_org_date\n","tks = spark.read.parquet(f\"{SILVER}/fact_tickets_daily\")\n","gold_tickets = (tks\n","    .select(\n","        \"org_id\",\"date\",\n","        F.col(\"sev\").alias(\"severity\"),\n","        F.col(\"tickets_opened\").cast(\"int\").alias(\"tickets_opened\"),\n","        F.col(\"sla_breach_count\").cast(\"int\").alias(\"sla_breach_count\"),\n","        \"csat_avg\"\n","    )\n",")\n","write_gold(gold_tickets, f\"{GOLD}/tickets_by_org_date\", [\"date\"])\n","print(\"✔ Gold: tickets_by_org_date\")\n","\n","# 5) Producto/GenAI: genai_tokens_by_org_date\n","TOKENS_COST_PER_1K = 0.002  # ajustar si tenés tarifa distinta\n","gold_genai = (usage\n","    .groupBy(\"org_id\",\"date\")\n","    .agg(F.sum(F.coalesce(\"genai_tokens\",F.lit(0.0))).alias(\"total_tokens\"))\n","    .withColumn(\"est_cost_usd\", (F.col(\"total_tokens\")/1000.0) * F.lit(TOKENS_COST_PER_1K))\n",")\n","write_gold(gold_genai, f\"{GOLD}/genai_tokens_by_org_date\", [\"date\"])\n","print(\"✔ Gold: genai_tokens_by_org_date\")\n","\n","# Checks\n","print(\"\\n=== CHECKS GOLD ===\")\n","spark.read.parquet(f\"{GOLD}/org_daily_usage_by_service\").limit(5).show(truncate=False)\n","spark.read.parquet(f\"{GOLD}/revenue_by_org_month\").limit(5).show(truncate=False)\n","spark.read.parquet(f\"{GOLD}/cost_anomaly_mart\").orderBy(F.desc(\"anomaly_flag\"),F.desc(\"daily_cost_usd\")).limit(5).show(truncate=False)\n","spark.read.parquet(f\"{GOLD}/tickets_by_org_date\").limit(5).show(truncate=False)\n","spark.read.parquet(f\"{GOLD}/genai_tokens_by_org_date\").limit(5).show(truncate=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OkHjIlTxshSj","executionInfo":{"status":"ok","timestamp":1762995150822,"user_tz":180,"elapsed":62029,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"bdb6e17f-d5c8-43ee-fbd5-6806147cc05e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✔ Gold: org_daily_usage_by_service\n","✔ Gold: revenue_by_org_month (swap aplicado)\n","✔ Gold: cost_anomaly_mart\n","✔ Gold: tickets_by_org_date\n","✔ Gold: genai_tokens_by_org_date\n","\n","=== CHECKS GOLD ===\n","+------------+------------------+--------+---------+------------------+------------+-------------------+----------+-------+\n","|org_id      |daily_cost_usd    |requests|cpu_hours|storage_gb_hours  |genai_tokens|carbon_kg          |date      |service|\n","+------------+------------------+--------+---------+------------------+------------+-------------------+----------+-------+\n","|org_kdgigatj|35.8909           |0.0     |0.0      |13.1736           |0.0         |0.084516           |2025-08-31|compute|\n","|org_3t60rjiw|0.6673            |0.0     |0.0      |9.5265            |0.0         |0.002054           |2025-08-31|compute|\n","|org_y9v86wzs|40.7354           |0.0     |0.0      |5.5961            |0.0         |0.09793600000000001|2025-08-31|compute|\n","|org_cwi64ciy|44.9063           |0.0     |0.0      |42.098800000000004|0.0         |0.106349           |2025-08-31|compute|\n","|org_pja1wj0t|11.927999999999999|0.0     |0.0      |14.4516           |0.0         |0.025482           |2025-08-31|compute|\n","+------------+------------------+--------+---------+------------------+------------+-------------------+----------+-------+\n","\n","+------------+-----------+------------+-----------+-------+-------+--------+------------+\n","|org_id      |revenue_usd|subtotal_usd|credits_usd|tax_usd|fx_rate|currency|month       |\n","+------------+-----------+------------+-----------+-------+-------+--------+------------+\n","|org_ujv6oh9s|NULL       |NULL        |979.51     |19.57  |205.7  |USD     |inv_zi3lplfw|\n","|org_zhwjr64d|NULL       |NULL        |816.1      |18.49  |171.38 |ARS     |inv_j2czafr0|\n","|org_cwi64ciy|NULL       |NULL        |1123.55    |18.42  |235.94 |USD     |inv_5prcpkfd|\n","|org_c11ertj5|NULL       |NULL        |1729.12    |9.97   |363.11 |EUR     |inv_zebcvf6f|\n","|org_dhylurtp|NULL       |NULL        |1150.2     |49.92  |241.54 |ARS     |inv_c8eanr1c|\n","+------------+-----------+------------+-----------+-------+-------+--------+------------+\n","\n","+------------+--------------+------------------+------------------+------------------+--------+--------+-------+---------+------------+----------+---------+\n","|org_id      |daily_cost_usd|zscore            |mad_score         |p95               |p99     |flag_p99|flag_z3|flag_mad3|anomaly_flag|date      |service  |\n","+------------+--------------+------------------+------------------+------------------+--------+--------+-------+---------+------------+----------+---------+\n","|org_d14ve92m|181.2338      |8.97172682231394  |32.41555567951507 |20.0437           |169.0774|true    |true   |true     |true        |2025-07-20|analytics|\n","|org_c11ertj5|170.7746      |13.37419726907924 |26.454971629944552|26.511899999999997|48.8655 |true    |true   |true     |true        |2025-08-31|compute  |\n","|org_253j2d54|169.0774      |8.342825163375952 |30.155203510533465|20.0437           |169.0774|false   |true   |true     |true        |2025-08-14|analytics|\n","|org_kdgigatj|128.2206      |13.996432890514052|31.447701939227358|13.495000000000001|25.6137 |true    |true   |true     |true        |2025-08-26|database |\n","|org_nam148p0|58.2786       |4.129351649302805 |8.269685262119914 |26.511899999999997|48.8655 |true    |true   |true     |true        |2025-08-30|compute  |\n","+------------+--------------+------------------+------------------+------------------+--------+--------+-------+---------+------------+----------+---------+\n","\n","+------------+--------+--------------+----------------+--------+----------+\n","|org_id      |severity|tickets_opened|sla_breach_count|csat_avg|date      |\n","+------------+--------+--------------+----------------+--------+----------+\n","|org_teiyzcot|low     |1             |0               |NULL    |2025-07-18|\n","|org_vyie6ivw|high    |1             |0               |NULL    |2025-07-18|\n","|org_zhwjr64d|low     |1             |0               |NULL    |2025-07-18|\n","|org_i7p5tb94|medium  |1             |0               |NULL    |2025-07-18|\n","|org_cwi64ciy|low     |1             |0               |NULL    |2025-07-18|\n","+------------+--------+--------------+----------------+--------+----------+\n","\n","+------------+------------+------------+----------+\n","|org_id      |total_tokens|est_cost_usd|date      |\n","+------------+------------+------------+----------+\n","|org_pht0hl9x|0.0         |0.0         |2025-08-30|\n","|org_pbhsahxt|4386.0      |0.008772    |2025-08-30|\n","|org_41ibljh7|0.0         |0.0         |2025-08-30|\n","|org_5lxo6qji|0.0         |0.0         |2025-08-30|\n","|org_8mdd4v30|0.0         |0.0         |2025-08-30|\n","+------------+------------+------------+----------+\n","\n"]}]},{"cell_type":"markdown","source":["Mini-fix en revenue_by_org_month"],"metadata":{"id":"4vOW1Ea1tLwe"}},{"cell_type":"code","source":["# RE-GENERAR SOLO revenue_by_org_month con coalesce defensivo\n","from pyspark.sql import functions as F\n","\n","SILVER = \"/content/datalake/silver\"\n","GOLD   = \"/content/datalake/gold\"\n","\n","bill = spark.read.parquet(f\"{SILVER}/fact_billing_monthly\")\n","bill = (bill\n","    .withColumn(\"subtotal_usd\", F.coalesce(\"subtotal_usd\", F.lit(0.0)))\n","    .withColumn(\"credits_usd\",  F.coalesce(\"credits_usd\",  F.lit(0.0)))\n","    .withColumn(\"tax_usd\",      F.coalesce(\"tax_usd\",      F.lit(0.0)))\n","    .withColumn(\"fx_rate\",      F.coalesce(\"fx_rate\",      F.lit(1.0)))\n","    .withColumn(\"revenue_usd\", (F.col(\"subtotal_usd\") - F.col(\"credits_usd\") + F.col(\"tax_usd\")) * F.col(\"fx_rate\"))\n","    .select(\"org_id\",\"month\",\"revenue_usd\",\"subtotal_usd\",\"credits_usd\",\"tax_usd\",\"fx_rate\",\"currency\")\n",")\n","(bill.write.mode(\"overwrite\").partitionBy(\"month\").parquet(f\"{GOLD}/revenue_by_org_month\"))\n","print(\"✔ Gold (revenue_by_org_month) regenerado con coalesce\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lhQrGOltMo6","executionInfo":{"status":"ok","timestamp":1762996932233,"user_tz":180,"elapsed":4492,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"007b46a3-1d11-4edb-e74a-4e63dfc05d7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✔ Gold (revenue_by_org_month) regenerado con coalesce\n"]}]},{"cell_type":"markdown","source":["Crear keyspace y tablas en Astra (CQL)"],"metadata":{"id":"cqpgyE5LtYf5"}},{"cell_type":"code","source":["KEYSPACE = \"cloud_analytics\"\n"],"metadata":{"id":"Fx45B4Qk4BcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ASTRA_BUNDLE = \"/content/secure-connect-cloud-analytics.zip\"\n","ASTRA_CLIENT_ID = \"privado\"\n","ASTRA_CLIENT_SECRET = \"privado\"\n"],"metadata":{"id":"iMh7OyMm6T9a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora ejecutá la carga Gold → Astra"],"metadata":{"id":"ofqOJmLl7NcQ"}},{"cell_type":"markdown","source":[],"metadata":{"id":"5zAnGd283y_w"}},{"cell_type":"code","source":["# === Carga GOLD -> AstraDB usando cassandra-driver (sin conector Spark) ===\n","!pip -q install cassandra-driver==3.29.1\n","\n","import datetime as dt\n","from cassandra.cluster import Cluster\n","from cassandra.auth import PlainTextAuthProvider\n","from cassandra.query import BatchStatement, PreparedStatement\n","from cassandra import ConsistencyLevel\n","\n","# 1) Conexión a Astra (usa TUS variables ya definidas)\n","cloud_config = {\"secure_connect_bundle\": ASTRA_BUNDLE}\n","auth_provider = PlainTextAuthProvider(ASTRA_CLIENT_ID, ASTRA_CLIENT_SECRET)\n","cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n","session = cluster.connect(\"cloud_analytics\")  # keyspace ya creado\n","\n","# 2) Utilidad: castear tipos Python correctos para CQL\n","def to_date(v):\n","    if v is None: return None\n","    if isinstance(v, dt.date): return v\n","    return dt.date.fromisoformat(str(v))\n","\n","def to_float(v):\n","    if v is None or v == \"\": return None\n","    try: return float(v)\n","    except: return None\n","\n","def to_int(v):\n","    if v is None or v == \"\": return None\n","    try: return int(v)\n","    except: return None\n","\n","# 3) Leemos GOLD con Spark (solo para leer Parquet local)\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()\n","GOLD = \"/content/datalake/gold\"\n","\n","# ---- Tabla 1: org_daily_usage_by_service ----\n","df1 = spark.read.parquet(f\"{GOLD}/org_daily_usage_by_service\").select(\n","    \"org_id\",\"date\",\"service\",\"daily_cost_usd\",\"requests\",\"cpu_hours\",\"storage_gb_hours\",\"genai_tokens\",\"carbon_kg\"\n",")\n","stmt1 = session.prepare(\"\"\"\n","INSERT INTO org_daily_usage_by_service\n","(org_id, date, service, daily_cost_usd, requests, cpu_hours, storage_gb_hours, genai_tokens, carbon_kg)\n","VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n","\"\"\")\n","batch_size = 200\n","batch = BatchStatement(consistency_level=ConsistencyLevel.QUORUM)\n","count = 0\n","for r in df1.toLocalIterator():\n","    batch.add(stmt1, (\n","        r[\"org_id\"], to_date(r[\"date\"]), r[\"service\"],\n","        to_float(r[\"daily_cost_usd\"]), to_float(r[\"requests\"]), to_float(r[\"cpu_hours\"]),\n","        to_float(r[\"storage_gb_hours\"]), to_float(r[\"genai_tokens\"]), to_float(r[\"carbon_kg\"])\n","    ))\n","    count += 1\n","    if len(batch) >= batch_size:\n","        session.execute(batch); batch.clear()\n","if len(batch) > 0: session.execute(batch)\n","print(f\"✔ Insertados org_daily_usage_by_service: {count}\")\n","\n","# ---- Tabla 2: revenue_by_org_month ----\n","df2 = spark.read.parquet(f\"{GOLD}/revenue_by_org_month\").select(\n","    \"org_id\",\"month\",\"revenue_usd\",\"subtotal_usd\",\"credits_usd\",\"tax_usd\",\"fx_rate\",\"currency\"\n",")\n","stmt2 = session.prepare(\"\"\"\n","INSERT INTO revenue_by_org_month\n","(org_id, month, revenue_usd, subtotal_usd, credits_usd, tax_usd, fx_rate, currency)\n","VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n","\"\"\")\n","batch = BatchStatement(consistency_level=ConsistencyLevel.QUORUM)\n","count = 0\n","for r in df2.toLocalIterator():\n","    batch.add(stmt2, (\n","        r[\"org_id\"], str(r[\"month\"]),\n","        to_float(r[\"revenue_usd\"]), to_float(r[\"subtotal_usd\"]), to_float(r[\"credits_usd\"]),\n","        to_float(r[\"tax_usd\"]), to_float(r[\"fx_rate\"]), r[\"currency\"]\n","    ))\n","    count += 1\n","    if len(batch) >= batch_size:\n","        session.execute(batch); batch.clear()\n","if len(batch) > 0: session.execute(batch)\n","print(f\"✔ Insertados revenue_by_org_month: {count}\")\n","\n","# ---- Tabla 3: cost_anomaly_mart ----\n","df3 = spark.read.parquet(f\"{GOLD}/cost_anomaly_mart\").select(\n","    \"org_id\",\"date\",\"service\",\"daily_cost_usd\",\"zscore\",\"mad_score\",\"p95\",\"p99\",\n","    \"flag_p99\",\"flag_z3\",\"flag_mad3\",\"anomaly_flag\"\n",")\n","stmt3 = session.prepare(\"\"\"\n","INSERT INTO cost_anomaly_mart\n","(org_id, date, service, daily_cost_usd, zscore, mad_score, p95, p99, flag_p99, flag_z3, flag_mad3, anomaly_flag)\n","VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n","\"\"\")\n","batch = BatchStatement(consistency_level=ConsistencyLevel.QUORUM)\n","count = 0\n","for r in df3.toLocalIterator():\n","    batch.add(stmt3, (\n","        r[\"org_id\"], to_date(r[\"date\"]), r[\"service\"],\n","        to_float(r[\"daily_cost_usd\"]), to_float(r[\"zscore\"]), to_float(r[\"mad_score\"]),\n","        to_float(r[\"p95\"]), to_float(r[\"p99\"]),\n","        bool(r[\"flag_p99\"]), bool(r[\"flag_z3\"]), bool(r[\"flag_mad3\"]), bool(r[\"anomaly_flag\"])\n","    ))\n","    count += 1\n","    if len(batch) >= batch_size:\n","        session.execute(batch); batch.clear()\n","if len(batch) > 0: session.execute(batch)\n","print(f\"✔ Insertados cost_anomaly_mart: {count}\")\n","\n","# ---- Tabla 4: tickets_by_org_date ----\n","df4 = spark.read.parquet(f\"{GOLD}/tickets_by_org_date\").select(\n","    \"org_id\",\"date\",\"severity\",\"tickets_opened\",\"sla_breach_count\",\"csat_avg\"\n",")\n","stmt4 = session.prepare(\"\"\"\n","INSERT INTO tickets_by_org_date\n","(org_id, date, severity, tickets_opened, sla_breach_count, csat_avg)\n","VALUES (?, ?, ?, ?, ?, ?)\n","\"\"\")\n","batch = BatchStatement(consistency_level=ConsistencyLevel.QUORUM)\n","count = 0\n","for r in df4.toLocalIterator():\n","    batch.add(stmt4, (\n","        r[\"org_id\"], to_date(r[\"date\"]), r[\"severity\"],\n","        to_int(r[\"tickets_opened\"]), to_int(r[\"sla_breach_count\"]), to_float(r[\"csat_avg\"])\n","    ))\n","    count += 1\n","    if len(batch) >= batch_size:\n","        session.execute(batch); batch.clear()\n","if len(batch) > 0: session.execute(batch)\n","print(f\"✔ Insertados tickets_by_org_date: {count}\")\n","\n","# ---- Tabla 5: genai_tokens_by_org_date ----\n","df5 = spark.read.parquet(f\"{GOLD}/genai_tokens_by_org_date\").select(\n","    \"org_id\",\"date\",\"total_tokens\",\"est_cost_usd\"\n",")\n","stmt5 = session.prepare(\"\"\"\n","INSERT INTO genai_tokens_by_org_date\n","(org_id, date, total_tokens, est_cost_usd)\n","VALUES (?, ?, ?, ?)\n","\"\"\")\n","batch = BatchStatement(consistency_level=ConsistencyLevel.QUORUM)\n","count = 0\n","for r in df5.toLocalIterator():\n","    batch.add(stmt5, (\n","        r[\"org_id\"], to_date(r[\"date\"]),\n","        to_float(r[\"total_tokens\"]), to_float(r[\"est_cost_usd\"])\n","    ))\n","    count += 1\n","    if len(batch) >= batch_size:\n","        session.execute(batch); batch.clear()\n","if len(batch) > 0: session.execute(batch)\n","print(f\"✔ Insertados genai_tokens_by_org_date: {count}\")\n","\n","print(\"🚀 Carga Gold → AstraDB finalizada con cassandra-driver\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGbENupb3yoP","executionInfo":{"status":"ok","timestamp":1762999274522,"user_tz":180,"elapsed":38641,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"81d3246b-ba34-465a-ee9c-97c7a4a79fae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]},{"output_type":"stream","name":"stderr","text":["WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:9e3a5bee-3d95-3bf7-90f5-09bd2177324b. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n","WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:9e3a5bee-3d95-3bf7-90f5-09bd2177324b. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n","WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:9e3a5bee-3d95-3bf7-90f5-09bd2177324b. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n","WARNING:cassandra.protocol:Server warning: `USE <keyspace>` with prepared statements is considered to be an anti-pattern due to ambiguity in non-qualified table names. Please consider removing instances of `Session#setKeyspace(<keyspace>)`, `Session#execute(\"USE <keyspace>\")` and `cluster.newSession(<keyspace>)` from your code, and always use fully qualified table names (e.g. <keyspace>.<table>). Keyspace used: 34613833663462632d323936322d343235332d396466662d626564353464323663636536_cloud_analytics, statement keyspace: 34613833663462632d323936322d343235332d396466662d626564353464323663636536_cloud_analytics, statement id: 61abde52df809fc63459311d558e63a4\n"]},{"output_type":"stream","name":"stdout","text":["✔ Insertados org_daily_usage_by_service: 1685\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:cassandra.protocol:Server warning: `USE <keyspace>` with prepared statements is considered to be an anti-pattern due to ambiguity in non-qualified table names. Please consider removing instances of `Session#setKeyspace(<keyspace>)`, `Session#execute(\"USE <keyspace>\")` and `cluster.newSession(<keyspace>)` from your code, and always use fully qualified table names (e.g. <keyspace>.<table>). Keyspace used: 34613833663462632d323936322d343235332d396466662d626564353464323663636536_cloud_analytics, statement keyspace: 34613833663462632d323936322d343235332d396466662d626564353464323663636536_cloud_analytics, statement id: 75dcb16ec8846abea85f2a42af0c0899\n"]},{"output_type":"stream","name":"stdout","text":["✔ Insertados revenue_by_org_month: 240\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:cassandra.protocol:Server warning: `USE <keyspace>` with prepared statements is considered to be an anti-pattern due to ambiguity in non-qualified table names. Please consider removing instances of `Session#setKeyspace(<keyspace>)`, `Session#execute(\"USE <keyspace>\")` and `cluster.newSession(<keyspace>)` from your code, and always use fully qualified table names (e.g. <keyspace>.<table>). Keyspace used: 34613833663462632d323936322d343235332d396466662d626564353464323663636536_cloud_analytics, statement keyspace: 34613833663462632d323936322d343235332d396466662d626564353464323663636536_cloud_analytics, statement id: c97b48b60e88b23642fed21895f7506a\n"]},{"output_type":"stream","name":"stdout","text":["✔ Insertados cost_anomaly_mart: 1685\n","✔ Insertados tickets_by_org_date: 984\n","✔ Insertados genai_tokens_by_org_date: 1336\n","🚀 Carga Gold → AstraDB finalizada con cassandra-driver\n"]}]},{"cell_type":"markdown","source":["costos/requests diarios en un rango (loop por día"],"metadata":{"id":"j5MPtojZ-amF"}},{"cell_type":"code","source":["import datetime as dt\n","from collections import defaultdict\n","\n","org = \"org_cwi64ciy\"\n","start, end = dt.date(2025,8,1), dt.date(2025,8,31)\n","\n","stmt = session.prepare(\"\"\"\n","SELECT date, service, daily_cost_usd, requests, cpu_hours, storage_gb_hours\n","FROM cloud_analytics.org_daily_usage_by_service\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","\n","rows = []\n","d = start\n","while d <= end:\n","    rows.extend(session.execute(stmt, (org, d)))\n","    d += dt.timedelta(days=1)\n","\n","# resumen por servicio\n","tot_cost = defaultdict(float)\n","tot_req  = defaultdict(float)\n","for r in rows:\n","    tot_cost[r.service] += float(r.daily_cost_usd or 0.0)\n","    tot_req[r.service]  += float(r.requests or 0.0)\n","\n","print(\"Costos por servicio (rango):\", dict(sorted(tot_cost.items())))\n","print(\"Requests por servicio (rango):\", dict(sorted(tot_req.items())))\n","print(\"Registros devueltos:\", len(rows))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klzlXRzH-Wn1","executionInfo":{"status":"ok","timestamp":1762999782683,"user_tz":180,"elapsed":4762,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"4bafb2f3-20a5-490c-b56e-da5f217c0aa0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Costos por servicio (rango): {'compute': 137.23059999999998, 'networking': 3.8691999999999998}\n","Requests por servicio (rango): {'compute': 0.0, 'networking': 0.0}\n","Registros devueltos: 12\n"]}]},{"cell_type":"markdown","source":["Top-N servicios por costo (últimos 14 días)"],"metadata":{"id":"QcPv_7K0-i0d"}},{"cell_type":"code","source":["from collections import defaultdict\n","org = \"org_cwi64ciy\"\n","start, end = dt.date(2025,10,30), dt.date(2025,11,12)\n","\n","stmt = session.prepare(\"\"\"\n","SELECT date, service, daily_cost_usd\n","FROM cloud_analytics.org_daily_usage_by_service\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","\n","agg = defaultdict(float)\n","d = start\n","while d <= end:\n","    for r in session.execute(stmt, (org, d)):\n","        agg[r.service] += float(r.daily_cost_usd or 0.0)\n","    d += dt.timedelta(days=1)\n","\n","topN = sorted(agg.items(), key=lambda x: x[1], reverse=True)[:5]\n","print(\"Top-5 servicios por costo (14d):\", topN)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ed6W-Q-C-jxF","executionInfo":{"status":"ok","timestamp":1762999823237,"user_tz":180,"elapsed":1875,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"a6311fcb-874e-443a-dad8-51a18e5ce41b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top-5 servicios por costo (14d): []\n"]}]},{"cell_type":"markdown","source":["críticos y SLA breach rate (últimos 30 días)"],"metadata":{"id":"PKQoTI14-sN8"}},{"cell_type":"code","source":["org = \"org_cwi64ciy\"\n","start, end = dt.date(2025,10,13), dt.date(2025,11,12)\n","\n","stmt = session.prepare(\"\"\"\n","SELECT date, severity, tickets_opened, sla_breach_count, csat_avg\n","FROM cloud_analytics.tickets_by_org_date\n","WHERE org_id = ? AND date = ? AND severity = 'critical';\n","\"\"\")\n","\n","series = []\n","d = start\n","while d <= end:\n","    opened = breach = 0\n","    for r in session.execute(stmt, (org, d)):\n","        opened += int(r.tickets_opened or 0)\n","        breach += int(r.sla_breach_count or 0)\n","    rate = (breach / opened) if opened else 0.0\n","    series.append((d, opened, breach, rate))\n","    d += dt.timedelta(days=1)\n","\n","print(\"Primeros 10 días (fecha, tickets, breaches, breach_rate):\")\n","for s in series[:10]:\n","    print(s)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flE-rJ-s-tB9","executionInfo":{"status":"ok","timestamp":1762999861021,"user_tz":180,"elapsed":3384,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"b4797d1e-f0a4-4470-9b56-39d4dd453f6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Primeros 10 días (fecha, tickets, breaches, breach_rate):\n","(datetime.date(2025, 10, 13), 0, 0, 0.0)\n","(datetime.date(2025, 10, 14), 0, 0, 0.0)\n","(datetime.date(2025, 10, 15), 0, 0, 0.0)\n","(datetime.date(2025, 10, 16), 0, 0, 0.0)\n","(datetime.date(2025, 10, 17), 0, 0, 0.0)\n","(datetime.date(2025, 10, 18), 0, 0, 0.0)\n","(datetime.date(2025, 10, 19), 0, 0, 0.0)\n","(datetime.date(2025, 10, 20), 0, 0, 0.0)\n","(datetime.date(2025, 10, 21), 0, 0, 0.0)\n","(datetime.date(2025, 10, 22), 0, 0, 0.0)\n"]}]},{"cell_type":"code","source":["# === Re-cargar revenue_by_org_month usando cassandra-driver (sin conector Spark) ===\n","!pip -q install cassandra-driver==3.29.1\n","\n","from cassandra.cluster import Cluster\n","from cassandra.auth import PlainTextAuthProvider\n","from cassandra.query import BatchStatement\n","from cassandra import ConsistencyLevel\n","from pyspark.sql import functions as F\n","\n","KEYSPACE = \"cloud_analytics\"\n","GOLD = \"/content/datalake/gold\"\n","\n","# 1) Conexión a Astra (reutiliza tus variables ASTRA_BUNDLE/ID/SECRET)\n","cloud_config = {\"secure_connect_bundle\": ASTRA_BUNDLE}\n","auth_provider = PlainTextAuthProvider(ASTRA_CLIENT_ID, ASTRA_CLIENT_SECRET)\n","cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n","session = cluster.connect()\n","\n","# 2) TRUNCATE tabla en Astra\n","session.execute(f\"TRUNCATE {KEYSPACE}.revenue_by_org_month;\")\n","print(\"✔ TRUNCATE revenue_by_org_month\")\n","\n","# 3) Leer parquet GOLD y corregir cruce org_id/month\n","rev = spark.read.parquet(f\"{GOLD}/revenue_by_org_month\").select(\n","    \"org_id\",\"month\",\"revenue_usd\",\"subtotal_usd\",\"credits_usd\",\"tax_usd\",\"fx_rate\",\"currency\"\n",")\n","\n","# detecta filas mal mapeadas (org_id=inv_*, month=org_*)\n","bad = rev.filter(F.col(\"org_id\").startswith(\"inv_\") & F.col(\"month\").startswith(\"org_\"))\n","good = rev.exceptAll(bad)\n","\n","fixed_bad = bad.select(\n","    F.col(\"month\").alias(\"org_id\"),\n","    F.col(\"org_id\").alias(\"month\"),\n","    \"revenue_usd\",\"subtotal_usd\",\"credits_usd\",\"tax_usd\",\"fx_rate\",\"currency\"\n",")\n","\n","fixed = good.unionByName(fixed_bad)\n","\n","# 4) Insertar en Astra por batches\n","stmt = session.prepare(f\"\"\"\n","INSERT INTO {KEYSPACE}.revenue_by_org_month\n","(org_id, month, revenue_usd, subtotal_usd, credits_usd, tax_usd, fx_rate, currency)\n","VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n","\"\"\")\n","\n","def to_float(x):\n","    try:\n","        return float(x) if x is not None else None\n","    except:\n","        return None\n","\n","batch = BatchStatement(consistency_level=ConsistencyLevel.QUORUM)\n","count = 0\n","for r in fixed.toLocalIterator():\n","    batch.add(stmt, (\n","        r[\"org_id\"],\n","        str(r[\"month\"]),                      # month es texto 'YYYY-MM'\n","        to_float(r[\"revenue_usd\"]),\n","        to_float(r[\"subtotal_usd\"]),\n","        to_float(r[\"credits_usd\"]),\n","        to_float(r[\"tax_usd\"]),\n","        to_float(r[\"fx_rate\"]),\n","        r[\"currency\"]\n","    ))\n","    count += 1\n","    if len(batch) >= 200:\n","        session.execute(batch); batch.clear()\n","if len(batch) > 0:\n","    session.execute(batch)\n","\n","print(f\"🚀 Revenue corregido insertado: {count} filas\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vt2edx6aAlb3","executionInfo":{"status":"ok","timestamp":1763000375285,"user_tz":180,"elapsed":25924,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"773b074d-8d95-422f-c786-c8328caa0234"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:0669df0f-031f-383e-b452-67a9679bbc6a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n","WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:0669df0f-031f-383e-b452-67a9679bbc6a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n","WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:0669df0f-031f-383e-b452-67a9679bbc6a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"]},{"output_type":"stream","name":"stdout","text":["✔ TRUNCATE revenue_by_org_month\n","🚀 Revenue corregido insertado: 240 filas\n"]}]},{"cell_type":"code","source":["# ==== Recargar revenue_by_org_month (corrigiendo org_id/month) ====\n","!pip -q install cassandra-driver==3.29.1\n","\n","import re, datetime as dt\n","from cassandra.cluster import Cluster\n","from cassandra.auth import PlainTextAuthProvider\n","from cassandra.query import BatchStatement\n","from cassandra import ConsistencyLevel\n","from pyspark.sql import functions as F\n","\n","KEYSPACE = \"cloud_analytics\"\n","GOLD = \"/content/datalake/gold\"\n","\n","# 1) Conexión a Astra (usa tus variables ASTRA_BUNDLE / ASTRA_CLIENT_ID / ASTRA_CLIENT_SECRET ya definidas)\n","cloud_config = {\"secure_connect_bundle\": ASTRA_BUNDLE}\n","auth_provider = PlainTextAuthProvider(ASTRA_CLIENT_ID, ASTRA_CLIENT_SECRET)\n","cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n","session = cluster.connect()\n","\n","# 2) Vaciar la tabla antes de recargar\n","session.execute(f\"TRUNCATE {KEYSPACE}.revenue_by_org_month;\")\n","print(\"✔ TRUNCATE revenue_by_org_month\")\n","\n","# 3) Leer Parquet GOLD\n","rev = (spark.read.parquet(f\"{GOLD}/revenue_by_org_month\")\n","       .select(\"org_id\",\"month\",\"revenue_usd\",\"subtotal_usd\",\"credits_usd\",\"tax_usd\",\"fx_rate\",\"currency\"))\n","\n","# 4) Separar filas “malas” (org_id=inv_* y month=org_*) y “buenas”\n","bad  = rev.filter(F.col(\"org_id\").startswith(\"inv_\") & F.col(\"month\").startswith(\"org_\"))\n","good = rev.filter(~(F.col(\"org_id\").startswith(\"inv_\") & F.col(\"month\").startswith(\"org_\")))\n","\n","# 5) Hacer swap en las malas: org_id <- month ; month <- org_id\n","fixed_bad = bad.select(\n","    F.col(\"month\").alias(\"org_id\"),\n","    F.col(\"org_id\").alias(\"month\"),\n","    \"revenue_usd\",\"subtotal_usd\",\"credits_usd\",\"tax_usd\",\"fx_rate\",\"currency\"\n",")\n","\n","# 6) Unir corregidas + buenas\n","fixed = good.unionByName(fixed_bad)\n","\n","# 7) Normalizar 'month' a 'YYYY-MM' por si viniera 'YYYY-MM-DD' o tipo fecha\n","def normalize_month(v):\n","    if v is None:\n","        return None\n","    # objetos date/datetime\n","    if isinstance(v, (dt.date, dt.datetime)):\n","        return f\"{v.year:04d}-{v.month:02d}\"\n","    s = str(v)\n","    if re.match(r\"^\\d{4}-\\d{2}$\", s):\n","        return s\n","    if re.match(r\"^\\d{4}-\\d{2}-\\d{2}$\", s):\n","        return s[:7]\n","    # si todavía es algo raro, lo dejamos como string\n","    return s\n","\n","def fnum(x):\n","    try:\n","        return float(x) if x is not None else None\n","    except:\n","        return None\n","\n","# 8) Insertar en Astra por batches\n","stmt = session.prepare(f\"\"\"\n","INSERT INTO {KEYSPACE}.revenue_by_org_month\n","(org_id, month, revenue_usd, subtotal_usd, credits_usd, tax_usd, fx_rate, currency)\n","VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n","\"\"\")\n","\n","batch = BatchStatement(consistency_level=ConsistencyLevel.QUORUM)\n","count = 0\n","for r in fixed.toLocalIterator():\n","    month_norm = normalize_month(r[\"month\"])\n","    batch.add(stmt, (\n","        r[\"org_id\"],\n","        month_norm,\n","        fnum(r[\"revenue_usd\"]),\n","        fnum(r[\"subtotal_usd\"]),\n","        fnum(r[\"credits_usd\"]),\n","        fnum(r[\"tax_usd\"]),\n","        fnum(r[\"fx_rate\"]),\n","        r[\"currency\"]\n","    ))\n","    count += 1\n","    if len(batch) >= 200:\n","        session.execute(batch); batch.clear()\n","if len(batch) > 0:\n","    session.execute(batch)\n","\n","print(f\"🚀 Revenue corregido insertado: {count} filas\")\n","\n","# 9) Verificación rápida desde Python (muestra 1 org y sus meses)\n","rows = session.execute(f\"SELECT org_id, month, revenue_usd FROM {KEYSPACE}.revenue_by_org_month LIMIT 5;\")\n","sample_org = None\n","for rr in rows:\n","    print(\"Sample:\", rr)\n","    sample_org = rr.org_id\n","    break\n","\n","if sample_org:\n","    print(\"\\nMeses para:\", sample_org)\n","    for rr in session.execute(f\"\"\"\n","        SELECT month, revenue_usd FROM {KEYSPACE}.revenue_by_org_month\n","        WHERE org_id = %s\n","    \"\"\", (sample_org,)):\n","        print(rr.month, rr.revenue_usd)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYUBvVdqE2-g","executionInfo":{"status":"ok","timestamp":1763001488690,"user_tz":180,"elapsed":18345,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"32aa7ef2-ddd2-4f3b-b5f3-7f7f72404a6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:0750e59f-441b-37bb-b0a7-e097c5d725f7. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n","WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:0750e59f-441b-37bb-b0a7-e097c5d725f7. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n","WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:0750e59f-441b-37bb-b0a7-e097c5d725f7. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"]},{"output_type":"stream","name":"stdout","text":["✔ TRUNCATE revenue_by_org_month\n","🚀 Revenue corregido insertado: 240 filas\n","Sample: Row(org_id='org_c11ertj5', month='inv_8fkcek2g', revenue_usd=-236799.24000000002)\n","\n","Meses para: org_c11ertj5\n","inv_8fkcek2g -236799.24000000002\n","inv_ovk2hqkq -331061.4153\n","inv_zebcvf6f -624240.5565\n"]}]},{"cell_type":"code","source":["# ==== RECONSTRUIR revenue_by_org_month (correcto) y cargar a Astra con cassandra-driver ====\n","!pip -q install cassandra-driver==3.29.1\n","\n","import re, datetime as dt, os\n","from cassandra.cluster import Cluster\n","from cassandra.auth import PlainTextAuthProvider\n","from cassandra.query import BatchStatement\n","from cassandra import ConsistencyLevel\n","from pyspark.sql import functions as F\n","from pyspark.sql import types as T\n","\n","KEYSPACE = \"cloud_analytics\"\n","\n","# 0) Conexión a Astra (usa tus variables ASTRA_BUNDLE/ID/SECRET ya definidas)\n","cloud_config = {\"secure_connect_bundle\": ASTRA_BUNDLE}\n","auth_provider = PlainTextAuthProvider(ASTRA_CLIENT_ID, ASTRA_CLIENT_SECRET)\n","cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n","session = cluster.connect()\n","\n","# 1) Intentar leer de SILVER; si no, leer CSV de landing y construir\n","silver_path = \"/content/datalake/silver/finops/fact_billing_monthly\"\n","landing_csv = \"/content/drive/MyDrive/mineria de datos II/proyecto1/billing_monthly.csv\"\n","\n","df = None\n","if os.path.exists(silver_path):\n","    df = spark.read.parquet(silver_path)\n","    print(\"✓ Leído Silver:\", silver_path)\n","else:\n","    print(\"⚠ No se encontró Silver. Leyendo CSV de landing…\")\n","    df = (spark.read\n","          .option(\"header\", True)\n","          .option(\"inferSchema\", True)\n","          .csv(landing_csv))\n","\n","# 2) Normalizar columnas esperadas\n","# Intentamos mapear a: org_id, month(YYYY-MM), subtotal_usd, credits_usd, tax_usd, fx_rate, currency, revenue_usd\n","cols = [c.lower() for c in df.columns]\n","df = df.toDF(*cols)\n","\n","# Heurísticas de nombres\n","org_col = \"org_id\" if \"org_id\" in cols else (\"tenant_id\" if \"tenant_id\" in cols else None)\n","inv_date_col = \"invoice_date\" if \"invoice_date\" in cols else None\n","month_col = \"month\" if \"month\" in cols else None\n","subtotal_col = \"subtotal_usd\" if \"subtotal_usd\" in cols else (\"subtotal\" if \"subtotal\" in cols else None)\n","credits_col  = \"credits_usd\"  if \"credits_usd\"  in cols else (\"credits\"  if \"credits\"  in cols else None)\n","tax_col      = \"tax_usd\"      if \"tax_usd\"      in cols else (\"tax\"      if \"tax\"      in cols else None)\n","fx_col       = \"fx_rate\"      if \"fx_rate\"      in cols else None\n","cur_col      = \"currency\"     if \"currency\"     in cols else None\n","\n","# Si no hay month pero hay invoice_date, lo derivamos.\n","work = df\n","if month_col is None and inv_date_col is not None:\n","    work = work.withColumn(\"invoice_ts\", F.to_timestamp(F.col(inv_date_col)))\n","    work = work.withColumn(\"month\", F.date_format(F.col(\"invoice_ts\"), \"yyyy-MM\"))\n","    month_col = \"month\"\n","elif month_col is not None:\n","    # Si month viene como fecha completa, recortar a yyyy-MM\n","    work = work.withColumn(\"month\",\n","                           F.when(F.length(F.col(month_col)) == 7, F.col(month_col))\n","                            .otherwise(F.date_format(F.to_date(F.col(month_col)), \"yyyy-MM\")))\n","else:\n","    # Último recurso: si hay algún 'period' o similar\n","    for c in cols:\n","        if c.startswith(\"period\") or c.endswith(\"_month\"):\n","            work = work.withColumn(\"month\",\n","                                   F.when(F.length(F.col(c)) == 7, F.col(c))\n","                                    .otherwise(F.date_format(F.to_date(F.col(c)), \"yyyy-MM\")))\n","            month_col = \"month\"\n","            break\n","\n","# Cast numéricos con fallback\n","def try_float(col):\n","    return F.when(F.col(col).cast(\"double\").isNotNull(), F.col(col).cast(\"double\")).otherwise(F.lit(None).cast(\"double\"))\n","\n","if subtotal_col is None: subtotal_col = \"subtotal_usd\"\n","if credits_col  is None: credits_col  = \"credits_usd\"\n","if tax_col      is None: tax_col      = \"tax_usd\"\n","if fx_col       is None: fx_col       = \"fx_rate\"\n","if cur_col      is None: cur_col      = \"currency\"\n","\n","# Si faltan columnas, créalas en 0/NULL\n","for c, defv in [(subtotal_col, 0.0), (credits_col, 0.0), (tax_col, 0.0)]:\n","    if c not in work.columns:\n","        work = work.withColumn(c, F.lit(defv).cast(\"double\"))\n","\n","if fx_col not in work.columns:\n","    work = work.withColumn(fx_col, F.lit(None).cast(\"double\"))\n","if cur_col not in work.columns:\n","    work = work.withColumn(cur_col, F.lit(\"USD\"))\n","\n","if org_col is None or month_col is None:\n","    raise ValueError(\"No pude identificar org_id y/o month. Revisa las columnas del origen.\")\n","\n","work = (work\n","    .withColumn(\"org_id\", F.col(org_col))\n","    .withColumn(\"month\", F.col(month_col))\n","    .withColumn(\"subtotal_usd\", try_float(subtotal_col))\n","    .withColumn(\"credits_usd\",  try_float(credits_col))\n","    .withColumn(\"tax_usd\",      try_float(tax_col))\n","    .withColumn(\"fx_rate\",      try_float(fx_col))\n","    .withColumn(\"currency\",     F.col(cur_col))\n",")\n","\n","# revenue_usd: usamos el ya calculado si existe, sino: subtotal_usd - credits_usd + tax_usd\n","if \"revenue_usd\" in work.columns:\n","    work = work.withColumn(\"revenue_usd\", try_float(\"revenue_usd\"))\n","else:\n","    work = work.withColumn(\"revenue_usd\",\n","                           F.coalesce(F.col(\"subtotal_usd\"), F.lit(0.0)) -\n","                           F.coalesce(F.col(\"credits_usd\"),  F.lit(0.0)) +\n","                           F.coalesce(F.col(\"tax_usd\"),      F.lit(0.0)))\n","\n","# Normalizar month definitivamente a 'YYYY-MM'\n","work = work.withColumn(\"month\",\n","                       F.when(F.length(\"month\")==7, F.col(\"month\"))\n","                        .otherwise(F.date_format(F.to_date(\"month\"), \"yyyy-MM\")))\n","\n","# Selección final y drop nulos clave\n","final_rev = (work\n","    .select(\"org_id\",\"month\",\"revenue_usd\",\"subtotal_usd\",\"credits_usd\",\"tax_usd\",\"fx_rate\",\"currency\")\n","    .where(F.col(\"org_id\").isNotNull() & F.col(\"month\").isNotNull())\n","    .dropDuplicates([\"org_id\",\"month\"])\n",")\n","\n","print(\"Schema final:\")\n","final_rev.printSchema()\n","final_rev.show(5, False)\n","\n","# 2) Limpiar tabla antes de insertar (ya truncamos arriba)\n","session.execute(\"TRUNCATE cloud_analytics.revenue_by_org_month;\")\n","\n","# 3) Insertar por batches\n","stmt = session.prepare(\"\"\"\n","INSERT INTO cloud_analytics.revenue_by_org_month\n","(org_id, month, revenue_usd, subtotal_usd, credits_usd, tax_usd, fx_rate, currency)\n","VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n","\"\"\")\n","\n","def fnum(x):\n","    try: return float(x) if x is not None else None\n","    except: return None\n","\n","batch = BatchStatement(consistency_level=ConsistencyLevel.QUORUM)\n","count = 0\n","for r in final_rev.toLocalIterator():\n","    batch.add(stmt, (r[\"org_id\"],\n","                     str(r[\"month\"])[:7],\n","                     fnum(r[\"revenue_usd\"]), fnum(r[\"subtotal_usd\"]),\n","                     fnum(r[\"credits_usd\"]), fnum(r[\"tax_usd\"]),\n","                     fnum(r[\"fx_rate\"]), r[\"currency\"]))\n","    count += 1\n","    if len(batch) >= 200:\n","        session.execute(batch); batch.clear()\n","if len(batch) > 0: session.execute(batch)\n","\n","print(f\"🚀 Revenue correcto insertado: {count} filas\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WjfnZcd2G9Mp","executionInfo":{"status":"ok","timestamp":1763002046629,"user_tz":180,"elapsed":24581,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"40b6d29c-2187-43a3-ab4b-6a4e54d3e592"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:b4f6d9ed-0f1d-3f7a-82f1-a4a7ea4f84d4. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n","WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:b4f6d9ed-0f1d-3f7a-82f1-a4a7ea4f84d4. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n","WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 4a83f4bc-2962-4253-9dff-bed54d26cce6-eu-west-1.db.astra.datastax.com:29042:b4f6d9ed-0f1d-3f7a-82f1-a4a7ea4f84d4. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"]},{"output_type":"stream","name":"stdout","text":["⚠ No se encontró Silver. Leyendo CSV de landing…\n","Schema final:\n","root\n"," |-- org_id: string (nullable = true)\n"," |-- month: string (nullable = true)\n"," |-- revenue_usd: double (nullable = false)\n"," |-- subtotal_usd: double (nullable = true)\n"," |-- credits_usd: double (nullable = true)\n"," |-- tax_usd: double (nullable = true)\n"," |-- fx_rate: double (nullable = true)\n"," |-- currency: string (nullable = true)\n","\n","+------------+-------+-----------+------------+-----------+-------+-------+--------+\n","|org_id      |month  |revenue_usd|subtotal_usd|credits_usd|tax_usd|fx_rate|currency|\n","+------------+-------+-----------+------------+-----------+-------+-------+--------+\n","|org_0lvsnujz|2025-06|1316.02    |1316.02     |NULL       |0.0    |NULL   |ARS     |\n","|org_0lvsnujz|2025-07|1579.22    |1600.22     |21.0       |0.0    |NULL   |USD     |\n","|org_0lvsnujz|2025-08|675.07     |675.07      |NULL       |0.0    |NULL   |USD     |\n","|org_0lzjjege|2025-06|1179.39    |1179.39     |NULL       |0.0    |NULL   |ARS     |\n","|org_0lzjjege|2025-07|313.59     |319.01      |5.42       |0.0    |NULL   |ARS     |\n","+------------+-------+-----------+------------+-----------+-------+-------+--------+\n","only showing top 5 rows\n","\n","🚀 Revenue correcto insertado: 240 filas\n"]}]},{"cell_type":"markdown","source":["Costos y requests diarios por org y servicio (rango)"],"metadata":{"id":"GshcYAygHkci"}},{"cell_type":"code","source":["import datetime as dt\n","from collections import defaultdict\n","\n","org = \"org_c11ertj5\"\n","start, end = dt.date(2025,8,1), dt.date(2025,8,31)\n","\n","stmt = session.prepare(\"\"\"\n","SELECT date, service, daily_cost_usd, requests, cpu_hours, storage_gb_hours\n","FROM cloud_analytics.org_daily_usage_by_service\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","\n","rows = []\n","d = start\n","while d <= end:\n","    rows.extend(session.execute(stmt, (org, d)))\n","    d += dt.timedelta(days=1)\n","\n","# sumar por servicio (útil para el dashboard)\n","cost_by_service = defaultdict(float)\n","for r in rows:\n","    cost_by_service[r.service] += float(r.daily_cost_usd or 0.0)\n","\n","print(\"Registros:\", len(rows))\n","print(\"Costos por servicio:\", dict(sorted(cost_by_service.items())))\n"],"metadata":{"id":"F7xdQMrQHgsJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Top-N servicios por costo (últimos 14 días)"],"metadata":{"id":"To78X_85HqKS"}},{"cell_type":"code","source":["from collections import defaultdict\n","org = \"org_c11ertj5\"\n","start, end = dt.date(2025,10,30), dt.date(2025,11,12)\n","\n","stmt = session.prepare(\"\"\"\n","SELECT date, service, daily_cost_usd\n","FROM cloud_analytics.org_daily_usage_by_service\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","\n","agg = defaultdict(float)\n","d = start\n","while d <= end:\n","    for r in session.execute(stmt, (org, d)):\n","        agg[r.service] += float(r.daily_cost_usd or 0.0)\n","    d += dt.timedelta(days=1)\n","\n","topN = sorted(agg.items(), key=lambda x: x[1], reverse=True)[:5]\n","print(\"Top-5 servicios por costo (14d):\", topN)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZ5GfxXqHq5T","executionInfo":{"status":"ok","timestamp":1763002208832,"user_tz":180,"elapsed":1741,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"395c90bf-b24c-47ac-8f72-9bb40e8e0286"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top-5 servicios por costo (14d): []\n"]}]},{"cell_type":"markdown","source":["Evolución de críticos y tasa de SLA breach (30 días)"],"metadata":{"id":"LDn58KRXHv36"}},{"cell_type":"code","source":["org = \"org_c11ertj5\"\n","start, end = dt.date(2025,10,13), dt.date(2025,11,12)\n","\n","stmt = session.prepare(\"\"\"\n","SELECT date, severity, tickets_opened, sla_breach_count, csat_avg\n","FROM cloud_analytics.tickets_by_org_date\n","WHERE org_id = ? AND date = ? AND severity = 'critical';\n","\"\"\")\n","\n","series = []\n","d = start\n","while d <= end:\n","    opened = breach = 0\n","    for r in session.execute(stmt, (org, d)):\n","        opened += int(r.tickets_opened or 0)\n","        breach += int(r.sla_breach_count or 0)\n","    rate = (breach / opened) if opened else 0.0\n","    series.append((d, opened, breach, rate))\n","    d += dt.timedelta(days=1)\n","\n","print(\"Primeros días (fecha, tickets, breaches, breach_rate):\")\n","for s in series[:10]:\n","    print(s)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rNgmWX--Hw4C","executionInfo":{"status":"ok","timestamp":1763002236909,"user_tz":180,"elapsed":3597,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"89521a27-d04b-4d57-b0ba-5228c45b8853"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Primeros días (fecha, tickets, breaches, breach_rate):\n","(datetime.date(2025, 10, 13), 0, 0, 0.0)\n","(datetime.date(2025, 10, 14), 0, 0, 0.0)\n","(datetime.date(2025, 10, 15), 0, 0, 0.0)\n","(datetime.date(2025, 10, 16), 0, 0, 0.0)\n","(datetime.date(2025, 10, 17), 0, 0, 0.0)\n","(datetime.date(2025, 10, 18), 0, 0, 0.0)\n","(datetime.date(2025, 10, 19), 0, 0, 0.0)\n","(datetime.date(2025, 10, 20), 0, 0, 0.0)\n","(datetime.date(2025, 10, 21), 0, 0, 0.0)\n","(datetime.date(2025, 10, 22), 0, 0, 0.0)\n"]}]},{"cell_type":"markdown","source":["Costos/requests diarios por org y servicio (rango de fechas)"],"metadata":{"id":"zroJKrruJB7D"}},{"cell_type":"code","source":["org = \"org_c11ertj5\"\n","start, end = dt.date(2025,8,1), dt.date(2025,8,31)\n","\n","stmt = session.prepare(\"\"\"\n","SELECT date, total_tokens, est_cost_usd\n","FROM cloud_analytics.genai_tokens_by_org_date\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","\n","rows = []\n","d = start\n","while d <= end:\n","    rows.extend(session.execute(stmt, (org, d)))\n","    d += dt.timedelta(days=1)\n","\n","print(\"Filas:\", len(rows))\n","for r in rows[:10]:\n","    print(r.date, r.total_tokens, r.est_cost_usd)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mg-rw3rpIMCS","executionInfo":{"status":"ok","timestamp":1763002400835,"user_tz":180,"elapsed":3385,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"682368c8-7648-4e82-d5c6-038594d09b3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Filas: 8\n","2025-08-02 0.0 0.0\n","2025-08-03 0.0 0.0\n","2025-08-06 0.0 0.0\n","2025-08-09 0.0 0.0\n","2025-08-23 0.0 0.0\n","2025-08-27 0.0 0.0\n","2025-08-30 0.0 0.0\n","2025-08-31 3392.0 0.006784\n"]}]},{"cell_type":"markdown","source":["Top-N servicios por costo (últimos 14 días)"],"metadata":{"id":"-1HhEK5hI0pC"}},{"cell_type":"code","source":["from collections import defaultdict\n","org = \"org_c11ertj5\"\n","start, end = dt.date(2025,10,30), dt.date(2025,11,12)\n","\n","stmt = session.prepare(\"\"\"\n","SELECT date, service, daily_cost_usd\n","FROM cloud_analytics.org_daily_usage_by_service\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","\n","agg = defaultdict(float)\n","d = start\n","while d <= end:\n","    for r in session.execute(stmt, (org, d)):\n","        agg[r.service] += float(r.daily_cost_usd or 0.0)\n","    d += dt.timedelta(days=1)\n","\n","topN = sorted(agg.items(), key=lambda x: x[1], reverse=True)[:5]\n","print(\"Top-5 servicios por costo (14d):\", topN)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rN78utvuI1mK","executionInfo":{"status":"ok","timestamp":1763002594679,"user_tz":180,"elapsed":1670,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"9421c821-8b87-4d50-e08b-30a73ea024ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top-5 servicios por costo (14d): []\n"]}]},{"cell_type":"markdown","source":["Evolución de críticos y tasa de SLA breach (últimos 30 días)"],"metadata":{"id":"FfakC0g4JOX6"}},{"cell_type":"code","source":["org = \"org_c11ertj5\"\n","start, end = dt.date(2025,10,13), dt.date(2025,11,12)\n","\n","stmt = session.prepare(\"\"\"\n","SELECT date, severity, tickets_opened, sla_breach_count, csat_avg\n","FROM cloud_analytics.tickets_by_org_date\n","WHERE org_id = ? AND date = ? AND severity = 'critical';\n","\"\"\")\n","\n","series = []\n","d = start\n","while d <= end:\n","    opened = breach = 0\n","    for r in session.execute(stmt, (org, d)):\n","        opened += int(r.tickets_opened or 0)\n","        breach += int(r.sla_breach_count or 0)\n","    rate = (breach / opened) if opened else 0.0\n","    series.append((d, opened, breach, rate))\n","    d += dt.timedelta(days=1)\n","\n","print(\"Primeros 10 días (fecha, tickets, breaches, breach_rate):\")\n","for s in series[:10]:\n","    print(s)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EqMCLgO6JRWy","executionInfo":{"status":"ok","timestamp":1763002664726,"user_tz":180,"elapsed":3281,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"fab3ac9f-85cc-47b9-b1fa-c72ea349b6c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Primeros 10 días (fecha, tickets, breaches, breach_rate):\n","(datetime.date(2025, 10, 13), 0, 0, 0.0)\n","(datetime.date(2025, 10, 14), 0, 0, 0.0)\n","(datetime.date(2025, 10, 15), 0, 0, 0.0)\n","(datetime.date(2025, 10, 16), 0, 0, 0.0)\n","(datetime.date(2025, 10, 17), 0, 0, 0.0)\n","(datetime.date(2025, 10, 18), 0, 0, 0.0)\n","(datetime.date(2025, 10, 19), 0, 0, 0.0)\n","(datetime.date(2025, 10, 20), 0, 0, 0.0)\n","(datetime.date(2025, 10, 21), 0, 0, 0.0)\n","(datetime.date(2025, 10, 22), 0, 0, 0.0)\n"]}]},{"cell_type":"markdown","source":["Tokens GenAI y costo estimado por día (rango)"],"metadata":{"id":"Bw3XXIilJfCy"}},{"cell_type":"code","source":["org = \"org_c11ertj5\"\n","start, end = dt.date(2025,8,1), dt.date(2025,8,31)\n","\n","stmt = session.prepare(\"\"\"\n","SELECT date, total_tokens, est_cost_usd\n","FROM cloud_analytics.genai_tokens_by_org_date\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","\n","rows = []\n","d = start\n","while d <= end:\n","    rows.extend(session.execute(stmt, (org, d)))\n","    d += dt.timedelta(days=1)\n","\n","print(\"Filas:\", len(rows))\n","for r in rows[:10]:\n","    print(r.date, r.total_tokens, r.est_cost_usd)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqFLWPHJJf0K","executionInfo":{"status":"ok","timestamp":1763002709884,"user_tz":180,"elapsed":3384,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"03374e88-6e70-41ec-fe01-64353b6f94e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Filas: 8\n","2025-08-02 0.0 0.0\n","2025-08-03 0.0 0.0\n","2025-08-06 0.0 0.0\n","2025-08-09 0.0 0.0\n","2025-08-23 0.0 0.0\n","2025-08-27 0.0 0.0\n","2025-08-30 0.0 0.0\n","2025-08-31 3392.0 0.006784\n"]}]},{"cell_type":"code","source":["# ========= Pretty prints para las 4 consultas que corren desde Colab =========\n","import datetime as dt\n","from collections import defaultdict\n","\n","# --- Parámetros (modificá si querés) ---\n","org   = \"org_c11ertj5\"\n","r1    = (dt.date(2025,8,1),  dt.date(2025,8,31))   # #1 costos/requests rango\n","r2    = (dt.date(2025,10,30),dt.date(2025,11,12))  # #2 Top-N 14d\n","r3    = (dt.date(2025,10,13),dt.date(2025,11,12))  # #3 críticos 30d\n","r5    = (dt.date(2025,8,1),  dt.date(2025,8,31))   # #5 GenAI agosto\n","\n","# ---------------- #1 Costos/requests diarios por org y servicio (rango) ----------------\n","stmt1 = session.prepare(\"\"\"\n","SELECT date, service, daily_cost_usd, requests, cpu_hours, storage_gb_hours\n","FROM cloud_analytics.org_daily_usage_by_service\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","rows1 = []\n","d = r1[0]\n","while d <= r1[1]:\n","    rows1.extend(session.execute(stmt1, (org, d)))\n","    d += dt.timedelta(days=1)\n","\n","cost_by_service = defaultdict(float)\n","req_by_service  = defaultdict(float)\n","for r in rows1:\n","    cost_by_service[r.service] += float(r.daily_cost_usd or 0.0)\n","    req_by_service[r.service]  += float(r.requests or 0.0)\n","\n","print(\"=== #1 Costos/Requests diarios (rango) ===\")\n","print(f\"org = {org} | fechas = {r1[0]} .. {r1[1]} | filas = {len(rows1)}\\n\")\n","print(\"Servicio       | Costos USD total | Requests total\")\n","print(\"---------------+------------------+---------------\")\n","for svc in sorted(cost_by_service):\n","    print(f\"{svc:<14} | {cost_by_service[svc]:>16,.2f} | {req_by_service[svc]:>13,.0f}\")\n","print()\n","\n","# ---------------- #2 Top-N servicios por costo acumulado (14 días) ----------------\n","stmt2 = session.prepare(\"\"\"\n","SELECT date, service, daily_cost_usd\n","FROM cloud_analytics.org_daily_usage_by_service\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","agg2 = defaultdict(float)\n","d = r2[0]\n","while d <= r2[1]:\n","    for r in session.execute(stmt2, (org, d)):\n","        agg2[r.service] += float(r.daily_cost_usd or 0.0)\n","    d += dt.timedelta(days=1)\n","\n","topN = sorted(agg2.items(), key=lambda x: x[1], reverse=True)[:5]\n","print(\"=== #2 Top-N servicios por costo (últimos 14 días) ===\")\n","print(f\"org = {org} | fechas = {r2[0]} .. {r2[1]}\\n\")\n","print(\"Rank | Servicio      | Costo 14d (USD)\")\n","print(\"-----+---------------+----------------\")\n","for i,(svc,val) in enumerate(topN,1):\n","    print(f\"{i:>4} | {svc:<13} | {val:>14,.2f}\")\n","print()\n","\n","# ---------------- #3 Evolución críticos y SLA breach rate (30 días) ----------------\n","stmt3 = session.prepare(\"\"\"\n","SELECT date, severity, tickets_opened, sla_breach_count, csat_avg\n","FROM cloud_analytics.tickets_by_org_date\n","WHERE org_id = ? AND date = ? AND severity = 'critical';\n","\"\"\")\n","series3 = []\n","d = r3[0]\n","while d <= r3[1]:\n","    opened = breach = 0\n","    for r in session.execute(stmt3, (org, d)):\n","        opened += int(r.tickets_opened or 0)\n","        breach += int(r.sla_breach_count or 0)\n","    rate = (breach / opened) if opened else 0.0\n","    series3.append((d, opened, breach, rate))\n","    d += dt.timedelta(days=1)\n","\n","print(\"=== #3 Críticos y SLA breach rate (30d) ===\")\n","print(f\"org = {org} | fechas = {r3[0]} .. {r3[1]}\\n\")\n","print(\"Fecha       | Tickets | Breaches | Breach rate\")\n","print(\"------------+---------+----------+------------\")\n","for d,opened,breach,rate in series3[:15]:\n","    print(f\"{d} | {opened:>7d} | {breach:>8d} | {rate:>10.2%}\")\n","if len(series3) > 15:\n","    print(f\"... ({len(series3)-15} filas más)\")\n","print()\n","\n","# ---------------- #5 Tokens GenAI y costo estimado (rango) ----------------\n","stmt5 = session.prepare(\"\"\"\n","SELECT date, total_tokens, est_cost_usd\n","FROM cloud_analytics.genai_tokens_by_org_date\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","rows5 = []\n","d = r5[0]\n","while d <= r5[1]:\n","    rows5.extend(session.execute(stmt5, (org, d)))\n","    d += dt.timedelta(days=1)\n","\n","print(\"=== #5 GenAI tokens y costo (rango) ===\")\n","print(f\"org = {org} | fechas = {r5[0]} .. {r5[1]} | filas = {len(rows5)}\\n\")\n","print(\"Fecha       | Tokens      | Est. costo (USD)\")\n","print(\"------------+-------------+-----------------\")\n","for r in rows5:\n","    print(f\"{r.date} | {float(r.total_tokens or 0):>11,.0f} | {float(r.est_cost_usd or 0):>15,.6f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5pUDsd7wKroK","executionInfo":{"status":"ok","timestamp":1763003010123,"user_tz":180,"elapsed":11683,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"e07d2bfb-a466-4cb4-cb9e-701f5d130896"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== #1 Costos/Requests diarios (rango) ===\n","org = org_c11ertj5 | fechas = 2025-08-01 .. 2025-08-31 | filas = 13\n","\n","Servicio       | Costos USD total | Requests total\n","---------------+------------------+---------------\n","compute        |           173.27 |             0\n","database       |            25.93 |             0\n","genai          |            31.13 |             0\n","storage        |             4.98 |             0\n","\n","=== #2 Top-N servicios por costo (últimos 14 días) ===\n","org = org_c11ertj5 | fechas = 2025-10-30 .. 2025-11-12\n","\n","Rank | Servicio      | Costo 14d (USD)\n","-----+---------------+----------------\n","\n","=== #3 Críticos y SLA breach rate (30d) ===\n","org = org_c11ertj5 | fechas = 2025-10-13 .. 2025-11-12\n","\n","Fecha       | Tickets | Breaches | Breach rate\n","------------+---------+----------+------------\n","2025-10-13 |       0 |        0 |      0.00%\n","2025-10-14 |       0 |        0 |      0.00%\n","2025-10-15 |       0 |        0 |      0.00%\n","2025-10-16 |       0 |        0 |      0.00%\n","2025-10-17 |       0 |        0 |      0.00%\n","2025-10-18 |       0 |        0 |      0.00%\n","2025-10-19 |       0 |        0 |      0.00%\n","2025-10-20 |       0 |        0 |      0.00%\n","2025-10-21 |       0 |        0 |      0.00%\n","2025-10-22 |       0 |        0 |      0.00%\n","2025-10-23 |       0 |        0 |      0.00%\n","2025-10-24 |       0 |        0 |      0.00%\n","2025-10-25 |       0 |        0 |      0.00%\n","2025-10-26 |       0 |        0 |      0.00%\n","2025-10-27 |       0 |        0 |      0.00%\n","... (16 filas más)\n","\n","=== #5 GenAI tokens y costo (rango) ===\n","org = org_c11ertj5 | fechas = 2025-08-01 .. 2025-08-31 | filas = 8\n","\n","Fecha       | Tokens      | Est. costo (USD)\n","------------+-------------+-----------------\n","2025-08-02 |           0 |        0.000000\n","2025-08-03 |           0 |        0.000000\n","2025-08-06 |           0 |        0.000000\n","2025-08-09 |           0 |        0.000000\n","2025-08-23 |           0 |        0.000000\n","2025-08-27 |           0 |        0.000000\n","2025-08-30 |           0 |        0.000000\n","2025-08-31 |       3,392 |        0.006784\n"]}]},{"cell_type":"markdown","source":["## Conclusión\n","\n","Implementamos un pipeline **Lambda** con batch (maestros, NPS y facturación) y streaming (usage events) en PySpark, almacenando **Bronze/Silver/Gold** en **Parquet** y **sirviendo Gold en AstraDB (Cassandra)**. Aseguramos **calidad** con tipificación consistente, dedupe por `event_id`, reglas (p.ej. `cost_usd_increment ≥ -0.01`), manejo de **evolución de esquema** (`schema_version` v1/v2 con `carbon_kg` y `genai_tokens`) y **anomalías** (p99, z-score, MAD), con *quarantine* aparte. En **Silver** normalizamos y enriquecimos (joins) y calculamos métricas diarias (`daily_cost_usd`, `requests`, `cpu_hours`, `storage_gb_hours`, `genai_tokens`, `carbon_kg`). En **Gold** modelamos por **query-first**:\n","- `org_daily_usage_by_service ((org_id, date), service)`\n","- `revenue_by_org_month ((org_id), month=YYYY-MM)` *(reconstruido correctamente para rangos por mes)*\n","- `cost_anomaly_mart`, `tickets_by_org_date`, `genai_tokens_by_org_date`.\n","\n","El **serving** se resolvió con `cassandra-driver` (batches, idempotente por PK) y las **5 consultas** requeridas quedaron demostradas:\n","1) Costos/requests diarios por org/servicio: lectura diaria por PK y agregación en cliente.\n","2) Top-N 14 días: agregado por servicio sobre lecturas diarias.\n","3) Críticos y SLA breach rate 30 días: serie diaria con `breach/tickets`.\n","4) Revenue mensual USD: filtro por rango `month` (YYYY-MM) directo en CQL.\n","5) GenAI tokens & costo por día: lectura diaria por PK (ej. 2025-08-31 → 3.392 tokens / USD 0.006784).\n","\n","**Idempotencia**: checkpointing en streaming y upsert por PK en cargas. **Performance**: particionamiento Parquet, `repartition/coalesce` en escrituras, y consultas en Astra por partición (org_id + date).  \n","Como mejora futura, se sugiere materializar tablas “range-friendly” (PK `(org_id, date, …)`) para rangos por fecha directamente en CQL sin loop del cliente.\n"],"metadata":{"id":"MpwScZrbK4Fk"}},{"cell_type":"code","source":["# Usa el Gold en Parquet para detectar el último día con datos de ese org\n","from pyspark.sql import functions as F\n","\n","org = \"org_c11ertj5\"\n","GOLD = \"/content/datalake/gold\"\n","usage_g = spark.read.parquet(f\"{GOLD}/org_daily_usage_by_service\")\n","\n","mx = (usage_g.filter(F.col(\"org_id\")==org)\n","              .agg(F.max(\"date\").alias(\"max_date\"))\n","              .collect()[0][\"max_date\"])\n","print(\"max_date =\", mx)\n","\n","import datetime as dt\n","end = mx\n","start = end - dt.timedelta(days=13)\n","print(\"ventana 14d:\", start, \"->\", end)\n","\n","# Re-usa el driver de Cassandra para calcular Top-N en esa ventana\n","from collections import defaultdict\n","stmt = session.prepare(\"\"\"\n","SELECT date, service, daily_cost_usd\n","FROM cloud_analytics.org_daily_usage_by_service\n","WHERE org_id = ? AND date = ?;\n","\"\"\")\n","\n","agg = defaultdict(float)\n","d = start\n","while d <= end:\n","    for r in session.execute(stmt, (org, d)):\n","        agg[r.service] += float(r.daily_cost_usd or 0.0)\n","    d += dt.timedelta(days=1)\n","\n","topN = sorted(agg.items(), key=lambda x: x[1], reverse=True)[:5]\n","print(\"Top-5 servicios por costo (últimos 14 días del org):\")\n","for i,(svc,val) in enumerate(topN,1):\n","    print(f\"{i:>4} | {svc:<13} | {val:>14,.2f} USD\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wtbOSPXILT_b","executionInfo":{"status":"ok","timestamp":1763003166912,"user_tz":180,"elapsed":7593,"user":{"displayName":"Gianmarco Mauricio Rios","userId":"06821740459985368975"}},"outputId":"03b69a95-5872-497c-beeb-20e016f58dad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["max_date = 2025-08-31\n","ventana 14d: 2025-08-18 -> 2025-08-31\n","Top-5 servicios por costo (últimos 14 días del org):\n","   1 | compute       |         172.37 USD\n","   2 | genai         |          31.13 USD\n","   3 | database      |          19.98 USD\n","   4 | storage       |           2.82 USD\n"]}]},{"cell_type":"markdown","source":["Conclusiones\n","\n","Implementamos una arquitectura Lambda:\n","Batch (maestros, NPS y facturación) + Streaming (usage events) en PySpark, con Bronze → Silver → Gold en Parquet y serving en AstraDB (Cassandra).\n","\n","Calidad: tipificación consistente, dedupe por event_id, validaciones (p.ej. cost_usd_increment ≥ -0.01), manejo de evolución de esquema (v1/v2 con carbon_kg, genai_tokens), detección de anomalías (p99, z-score, MAD) y quarantine aparte.\n","\n","Silver: normalización + joins a dimensiones; cálculo de métricas diarias: daily_cost_usd, requests, cpu_hours, storage_gb_hours, genai_tokens, carbon_kg.\n","\n","Gold (query-first):\n","org_daily_usage_by_service, revenue_by_org_month (reconstruido a YYYY-MM), cost_anomaly_mart, tickets_by_org_date, genai_tokens_by_org_date.\n","\n","Serving: carga a Astra con cassandra-driver (batches, upsert por PK).\n","Idempotencia con checkpointing (streaming) y llaves naturales.\n","\n","Consultas requeridas (evidencia):\n","\n","Costos/requests diarios (rango): OK (agosto 2025, org_c11ertj5).\n","\n","Top-N 14 días: OK (2025-08-18..31) → compute, genai, database, storage.\n","\n","Críticos y SLA breach rate 30d: OK (sin incidentes → tasa 0%).\n","\n","Revenue mensual (USD): OK (org_c11ertj5 → 2025-07: 1255.59 ARS, 2025-08: 1061.88 USD).\n","\n","GenAI tokens/costo por día: OK (31/08: 3.392 tokens → $0.006784).\n","\n","Trabajo futuro / mejoras\n","\n","Modelo range-friendly en Cassandra: materializar tablas paralelas con PK (org_id, date, …) para soportar rangos por fecha directamente en CQL (evitar loops del cliente en #1/#3/#5).\n","\n","Expectations formales (Great Expectations/Deequ): versionar reglas, data docs y CI checks de calidad.\n","\n","Orquestación: programar batch (Airflow/Prefect) y monitoreo de streaming (alertas sobre watermarks y lag).\n","\n","Cost anomaly scoring: combinar p99/z/MAD en un score único (ponderado) y feedback loop con equipo FinOps.\n","\n","Catálogo/Diccionario de datos: publicar diccionario de campos claves (orígenes, tipos, unidades, semántica).\n","\n","Dashboards: Superset/Power BI con vistas por FinOps, Soporte y GenAI (tendencias, top-N, alertas de anomalías)."],"metadata":{"id":"3mQuD1PCLtJa"}},{"cell_type":"code","source":[],"metadata":{"id":"QsgHYAB1LuTq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**consultas**"],"metadata":{"id":"IZdB-utuNNHb"}},{"cell_type":"markdown","source":["-- (opcional) Crear keyspace si no existe\n","CREATE KEYSPACE IF NOT EXISTS cloud_analytics\n","WITH REPLICATION = {'class': 'NetworkTopologyStrategy', 'replication_factor': '3'};\n","\n","-- FinOps: uso diario por org y servicio\n","CREATE TABLE IF NOT EXISTS cloud_analytics.org_daily_usage_by_service (\n","  org_id text,\n","  date date,\n","  service text,\n","  daily_cost_usd double,\n","  requests double,\n","  cpu_hours double,\n","  storage_gb_hours double,\n","  genai_tokens double,\n","  carbon_kg double,\n","  PRIMARY KEY ((org_id, date), service)\n",");\n","\n","-- FinOps: revenue mensual normalizado a USD\n","CREATE TABLE IF NOT EXISTS cloud_analytics.revenue_by_org_month (\n","  org_id text,\n","  month text,         -- 'YYYY-MM'\n","  revenue_usd double,\n","  subtotal_usd double,\n","  credits_usd double,\n","  tax_usd double,\n","  fx_rate double,\n","  currency text,\n","  PRIMARY KEY ((org_id), month)\n",");\n","\n","-- FinOps: anomalías de costo\n","CREATE TABLE IF NOT EXISTS cloud_analytics.cost_anomaly_mart (\n","  org_id text,\n","  date date,\n","  service text,\n","  daily_cost_usd double,\n","  zscore double,\n","  mad_score double,\n","  p95 double,\n","  p99 double,\n","  flag_p99 boolean,\n","  flag_z3 boolean,\n","  flag_mad3 boolean,\n","  anomaly_flag boolean,\n","  PRIMARY KEY ((org_id, date), service)\n",");\n","\n","-- Soporte: tickets por org y fecha\n","CREATE TABLE IF NOT EXISTS cloud_analytics.tickets_by_org_date (\n","  org_id text,\n","  date date,\n","  severity text,\n","  tickets_opened int,\n","  sla_breach_count int,\n","  csat_avg double,\n","  PRIMARY KEY ((org_id, date), severity)\n",");\n","\n","-- Producto/GenAI: tokens por org y día\n","CREATE TABLE IF NOT EXISTS cloud_analytics.genai_tokens_by_org_date (\n","  org_id text,\n","  date date,\n","  total_tokens double,\n","  est_cost_usd double,\n","  PRIMARY KEY ((org_id, date))\n",");\n"],"metadata":{"id":"RxJ4dmwfNLTr"}},{"cell_type":"markdown","source":["**Nota: Por diseño de PK, en #1, #2 y #3 el rango de fechas se resolvió desde el cliente (loop diario). A continuación dejo los CQL por día que usamos (válidos para capturas) y el CQL directo para #4.**"],"metadata":{"id":"-9US5lfJNazU"}},{"cell_type":"markdown","source":["-- #1 Costos y requests diarios por org y servicio (ejemplo un día)\n","SELECT date, service, daily_cost_usd, requests, cpu_hours, storage_gb_hours\n","FROM cloud_analytics.org_daily_usage_by_service\n","WHERE org_id = 'org_c11ertj5'\n","  AND date = '2025-08-15';\n","-- #2 (Base para Top-N 14d) costo por servicio por día (agregado en cliente)\n","SELECT date, service, daily_cost_usd\n","FROM cloud_analytics.org_daily_usage_by_service\n","WHERE org_id = 'org_c11ertj5'\n","  AND date = '2025-08-31';\n","-- #3 Evolución de tickets críticos por día (ejemplo un día)\n","SELECT date, severity, tickets_opened, sla_breach_count, csat_avg\n","FROM cloud_analytics.tickets_by_org_date\n","WHERE org_id = 'org_c11ertj5'\n","  AND date = '2025-10-20'\n","  AND severity = 'critical';\n","-- #4 Revenue mensual (rango por 'YYYY-MM')  ← ejecutado y con resultados\n","SELECT month, revenue_usd, subtotal_usd, credits_usd, tax_usd, fx_rate, currency\n","FROM cloud_analytics.revenue_by_org_month\n","WHERE org_id = 'org_c11ertj5'\n","  AND month >= '2025-07' AND month <= '2025-09';\n","-- #5 GenAI tokens/costo por día (ejemplo un día)\n","SELECT date, total_tokens, est_cost_usd\n","FROM cloud_analytics.genai_tokens_by_org_date\n","WHERE org_id = 'org_c11ertj5'\n","  AND date = '2025-08-31';\n"],"metadata":{"id":"mD3zbLwKNcsr"}},{"cell_type":"markdown","source":[],"metadata":{"id":"PVru1XTzC83T"}},{"cell_type":"code","source":[],"metadata":{"id":"BmfoaPZ3C8hj"},"execution_count":null,"outputs":[]}]}